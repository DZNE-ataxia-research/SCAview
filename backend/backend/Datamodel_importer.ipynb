{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'django'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d265d61ebe18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# from models.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdjango\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdjongo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdjongo_models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdjango\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msettings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'django'"
     ]
    }
   ],
   "source": [
    "# from models.py\n",
    "from django.db.models import Model\n",
    "from djongo import models as djongo_models\n",
    "from django.conf import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from views.py\n",
    "#from django.contrib import messages as gui_messages\n",
    "#from django.contrib.messages import get_messages\n",
    "\n",
    "from upload.models import (\n",
    "    DatamodelSource,\n",
    "    DatamodelUnit,\n",
    "    DatamodelAttribute,\n",
    "    DatamodelCode,\n",
    "    DatamodelAttributeMapping,\n",
    "    DatamodelCodeMapping,\n",
    "    DatamodelCalculation,\n",
    "    UserFile,\n",
    ")\n",
    "\n",
    "from pymongo.errors import BulkWriteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple libraries\n",
    "import calendar\n",
    "import csv\n",
    "import re\n",
    "from datetime import date, datetime\n",
    "from collections import Counter\n",
    "\n",
    "# custom import\n",
    "from upload.BulkCreateManager import BulkCreateManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyExcel\n",
    "from pyexcel_io import save_data\n",
    "from pyexcel import get_book\n",
    "from pyexcel import get_sheet\n",
    "from pyexcel_io.constants import DB_DJANGO\n",
    "from pyexcel_io.database.common import DjangoModelImporter, DjangoModelImportAdapter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UCUM\n",
    "from pyucum.ucum import *\n",
    "import urllib\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "true_replacements = [True, \"True\", \"TRUE\", \"true\"]\n",
    "false_replacements = [False, \"False\", \"FALSE\", \"false\"]\n",
    "date_range_global = [\"1875-01-01\", datetime.today().strftime('%Y-%m-%d')]\n",
    "ucum_api_url = \"http://ucum.nlm.nih.gov/ucum-service/v1\"\n",
    "colname_map = {'Sources':            [\"Abbreviation\", \"Source\", \"PID_colname\",\n",
    "                                      \"SITE_colname\", \"TIMESTAMP_colname\", \"Header_offset\"],\n",
    "               'Units':              [\"Unit\", \"UCUM\", \"Description\"],\n",
    "               'Attributes':         [\"Active\", \"Topic\", \"Topic_Description\", \"Umbrella\", \"Umbrella_Description\",\n",
    "                                      \"Attribute\", \"Attribute_Description\", \"Attribute_Tooltip\",\n",
    "                                      \"Datatype\", \"Domain\", \"Unit\"],\n",
    "               'Codes':              [\"Active\", \"Code\", \"Code_Description\", \"Key\", \"Value\"],\n",
    "               'Attribute_Mappings': [\"Active\", \"Source\", \"Source_Attribute\", \"Target_Attribute\", \"Transformation\"],\n",
    "               'Code_Mappings':      [\"Active\", \"Code_Mapping\", \"Source_Value\", \"Source_Value_Description\",\n",
    "                                      \"Target_Equivalent\", \"Remarks\"],\n",
    "               'Calculations':       [\"Active\", \"Workbench\", \"Source\", \"Attribute\", \"Function\", \"Remarks\"]\n",
    "               }\n",
    "\n",
    "main_msg_queue = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toe_error(msg, queue=None):\n",
    "    if queue is not None:\n",
    "        queue.append(\"ERROR: \" + msg)\n",
    "        return queue\n",
    "    raise Exception(msg)\n",
    "\n",
    "def toe_warning(msg, queue=None):\n",
    "    if queue is not None:\n",
    "        queue.append(\"WARNING: \" + msg)\n",
    "        return queue\n",
    "    print(\"WARNING: \" + msg)\n",
    "\n",
    "def toe_info(msg, queue=None):\n",
    "    if queue is not None:\n",
    "        queue.append(\"INFO: \" + msg)\n",
    "        return queue\n",
    "    print(\"INFO: \" + msg)\n",
    "\n",
    "def throw_or_enqueue(what, msg, queue=None):\n",
    "    if what == \"error\":\n",
    "        toe_error(msg, queue)\n",
    "    elif what == \"warning\":\n",
    "        toe_warning(msg, queue)\n",
    "    elif what == \"info\":\n",
    "        toe_info(msg, queue)\n",
    "    else:\n",
    "        raise Warning(\"Could not assign '\" + msg + \"' to a valid message class!\")\n",
    "\n",
    "        \n",
    "# helper function for handling exceptions in list comparisons\n",
    "def catch(func, handle=lambda e: e, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        return handle(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_tables_data():\n",
    "    DataPoints.objects.all().delete()\n",
    "\n",
    "def drop_tables_mapping():\n",
    "    drop_tables_data()\n",
    "    DatamodelCalculation.objects.all().delete()\n",
    "    DatamodelAttributeMapping.objects.all().delete()\n",
    "    DatamodelCodeMapping.objects.all().delete()\n",
    "\n",
    "def drop_tables_core():\n",
    "    drop_tables_mapping()\n",
    "    DatamodelAttribute.objects.all().delete()\n",
    "    DatamodelCode.objects.all().delete()\n",
    "    DatamodelUnit.objects.all().delete()\n",
    "    DatamodelSource.objects.all().delete()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dependency_levels_core():\n",
    "    model_dependency_levels = [[DatamodelSource,\n",
    "                                DatamodelUnit,\n",
    "                                DatamodelCode,\n",
    "                                ],\n",
    "                               [DatamodelAttribute],\n",
    "                              ]\n",
    "    return model_dependency_levels\n",
    "\n",
    "def get_dependency_levels_mapping():\n",
    "    model_dependency_levels = [[DatamodelCodeMapping],\n",
    "                               [DatamodelAttributeMapping],\n",
    "                               [DatamodelCalculation],\n",
    "                              ]\n",
    "    return model_dependency_levels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header_indices(act_colnames, exp_colnames):\n",
    "    indices = {n: catch(lambda: act_colnames.index(n)) for n in exp_colnames}\n",
    "    #indices = {n: catch(lambda: act_colnames.index(exp_colnames[n])) for n in exp_colnames}\n",
    "    misses = [re.findall('\\'([^\\']*)\\'', miss.args[0])[0] for miss in indices.values() if\n",
    "              miss.__class__ is ValueError]\n",
    "    if misses:\n",
    "        msg = \"Could not find following column headers (format corrupt?):\\n\" + \"\\n\".join(misses)\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "    return indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bool_fields(model):\n",
    "    return [f.name for f in model._meta.fields if f.__class__.__name__ == 'BooleanField']\n",
    "\n",
    "\n",
    "def get_char_fields(model):\n",
    "    return [f.name for f in model._meta.fields if f.__class__.__name__ == 'CharField']\n",
    "\n",
    "\n",
    "def get_relations(model):\n",
    "    return [f for f in model._meta.fields if f.is_relation]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables usually acquired from the web interface (user inputs)\n",
    "filepath = \"C:/Users/sschaffner/sciebo/IDSNneu/DataModel/Zusammenf√ºhrung/DM20200826.xlsx\"\n",
    "header_line_core = {'Sources': 0,    # offset\n",
    "                    'Units': 0,\n",
    "                    'Attributes': 0,\n",
    "                    'Codes': 0,\n",
    "                    }\n",
    "header_line_mapping = {'Attribute_Mappings': 0,    # offset\n",
    "                       'Code_Mappings': 0,\n",
    "                       'Calculations': 0,\n",
    "                       }\n",
    "model2sheet_core = {DatamodelSource: 'Sources',\n",
    "                    DatamodelUnit: 'Units',\n",
    "                    DatamodelCode: 'Codes',\n",
    "                    DatamodelAttribute: 'Attributes',\n",
    "                    }\n",
    "model2sheet_mapping = {DatamodelAttributeMapping: 'Attribute_Mappings',\n",
    "                       DatamodelCodeMapping: 'Code_Mappings',\n",
    "                       DatamodelCalculation: 'Calculations',\n",
    "                       }\n",
    "\n",
    "write_modes = [(\"new\", \"Drop complete datamodel before loading file\"),\n",
    "               (\"add\", \"Leave existing entries untouched, append your new ones\"),\n",
    "               ]\n",
    "write_mode = write_modes[0][0]    # \"add\" - \"new\" waere eine Einstellung *nur* fuer uns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks on numerical values, mainly dedicated to def check_domain\n",
    "\n",
    "def represents_int(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def lossless_float2int(numstring):\n",
    "    if numstring.count(\".\") == 1:\n",
    "        integer, decimal = numstring.split(\".\")\n",
    "        if represents_int(integer):\n",
    "            if not decimal or (represents_int(decimal) and int(decimal) == 0):\n",
    "                msg = \"Converted '\" + numstring + \"' to integer '\" + integer + \"' (lossless)\"\n",
    "                throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "                return integer\n",
    "    msg = \"Could not convert float value to integer number: \" + numstring\n",
    "    throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_int_array_and_sanitize(str_int):\n",
    "    int_range_pattern = re.compile(\"(^(-?\\d)?\\d*:(-?\\d)?\\d*$)|(^(-?\\d)?\\d*$)\")\n",
    "    elements = str_int.split(\",\")\n",
    "    misfits = [i for i in range(len(elements)) if not int_range_pattern.match(elements[i])]\n",
    "    for m in misfits:\n",
    "        x = elements[m].split(\":\")\n",
    "        if len(x) > 2:\n",
    "            return False\n",
    "        try:\n",
    "            elements[m] = \":\".join([str(f) for f in [lossless_float2int(x[i]) if x[i] else \"\" for i in range(len(x))]])\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return \",\".join(elements)\n",
    "\n",
    "\n",
    "def check_float_array_and_sanitize(str_float):\n",
    "    float_range_pattern = re.compile(\"(^(-\\d+)|(\\d+)\\.\\d+$)|(^((-\\d+)|(\\d+)\\.\\d+)?:((-\\d+)|(\\d+)\\.\\d+)?$)\")\n",
    "    elements = str_float.split(\",\")\n",
    "    misfits = [i for i in range(len(elements)) if not float_range_pattern.match(elements[i])]\n",
    "    for m in misfits:\n",
    "        x = elements[m].split(\":\")\n",
    "        if len(x) > 2:\n",
    "            return False\n",
    "        try:\n",
    "            elements[m] = \":\".join([str(f) for f in [float(x[i]) if x[i] else \"\" for i in range(len(x))]])\n",
    "        except ValueError:\n",
    "            return False\n",
    "    return \",\".join(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks on date values\n",
    "\n",
    "def sanitize_date(d):\n",
    "    # remove time stamp\n",
    "    old = d\n",
    "    d = re.compile(\"[0-9][0-9]:[0-9][0-9]:[0-9][0-9]\").sub(\"\", d)\n",
    "    if not d == old:\n",
    "        msg = \"Removed timestamp from date.\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "\n",
    "    # remove leading/trailing spaces\n",
    "    old = d\n",
    "    d = d.strip()\n",
    "    if not len(old) == len(d):\n",
    "        msg = \"Removed leading/trailing whitespaces.\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "\n",
    "    # if dot \".\" as separator: apply dash \"-\"\n",
    "    old = d\n",
    "    d = d.replace(\".\", \"-\")\n",
    "    if not d == old:\n",
    "        throw_or_enqueue(\"info\", \"Replaced '.' with correct separators '-'.\", main_msg_queue)\n",
    "\n",
    "    # remove leading/trailing separators\n",
    "    old = d\n",
    "    d = d.strip(\"-\")\n",
    "    if not len(old) == len(d):\n",
    "        msg = \"Removed dangling separators.\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "\n",
    "    # for incomplete dates: add \"00\" blocks as placeholder\n",
    "    dash_cnt = d.count(\"-\")\n",
    "    if dash_cnt == 1:\n",
    "        # messages.warning(\"Incomplete date - added day field '00'\")\n",
    "        if re.compile(\"^[0-9][0-9][0-9][0-9]-[0-9][0-9]\").match(d):    # trailing month in template (preferred)\n",
    "            msg = \"Incomplete date - added day field '00'\"\n",
    "            throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "            return d + \"-00\"\n",
    "        elif re.compile(\"^[0-9][0-9]-[0-9][0-9][0-9][0-9]\").match(d):  # leading month in template (to be corrected later)\n",
    "            msg = \"Incomplete date - added day field '00'\"\n",
    "            throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "            return \"00-\" + d\n",
    "        else:\n",
    "            msg = \"Invalid partial date pattern: '\" + d + \"'\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            return False\n",
    "    elif dash_cnt == 0:\n",
    "        msg = \"Incomplete date - added day and month fields '00'\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "        return d + \"-00-00\"\n",
    "    elif dash_cnt != 2:\n",
    "        msg = \"Inadequate number of separators (\" + str(dash_cnt) + \") found!\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "    else:\n",
    "        return d\n",
    "\n",
    "\n",
    "def reverse_date(d):\n",
    "    return \"-\".join(reversed(d.split(\"-\")))\n",
    "\n",
    "\n",
    "def check_date_pattern(d, sanitize):\n",
    "    pat_msg = \"'YYYY-MM-DD' required, with '00' legal for 'DD' and 'MM'\"\n",
    "    pattern = re.compile(\"^[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]$\")\n",
    "    if pattern.match(d):\n",
    "        return d\n",
    "    elif not sanitize:\n",
    "        return False\n",
    "\n",
    "    rev_d = reverse_date(d)\n",
    "    if pattern.match(rev_d):\n",
    "        msg = \"Reversed date sequence - \" + pat_msg\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "        return rev_d\n",
    "\n",
    "    if re.compile(\"^[0-9][0-9]-\").match(d):\n",
    "        msg = \"No valid date pattern! (presumably two-digit YEAR expression - \" + pat_msg + \")\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "        return False\n",
    "    elif re.compile(\"^[0-9][0-9][0-9][0-9]-[0-9]-[0-9][0-9]$\").match(d):\n",
    "        msg = \"No valid date pattern! (presumably single-digit MONTH expression - \" + pat_msg + \")\"\n",
    "        if not sanitize:\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            return False\n",
    "    elif re.compile(\"^[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9]$\").match(d):\n",
    "        msg = \"No valid date pattern! (presumably single-digit DAY expression - \" + pat_msg + \")\"\n",
    "        if not sanitize:\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            return False\n",
    "    elif re.compile(\"^[0-9][0-9][0-9][0-9]-[0-9]-[0-9]$\").match(d):\n",
    "        msg = \"No valid date pattern! (presumably single-digit MONTH and DAY expression - \" + pat_msg + \")\"\n",
    "        if not sanitize:\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            return False\n",
    "    \n",
    "    throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "    year, month, day = d.split(\"-\")\n",
    "    if len(month) == 1:\n",
    "        month = \"0\" + month\n",
    "    if len(day) == 1:\n",
    "        day = \"0\" + day\n",
    "\n",
    "    # recursion (effectively single iteration)\n",
    "    d = check_date_pattern(year + \"-\" + month + \"-\" + day, sanitize=False)\n",
    "\n",
    "    if d:\n",
    "        msg = \"Sanitized invalid date format.\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "        return d\n",
    "    msg = \"No valid date pattern! (attempts to sanitize failed)\"\n",
    "    throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "    return False\n",
    "\n",
    "\n",
    "def calculate_date_object(d):\n",
    "    year, month, day = d.split(\"-\")\n",
    "    return date(int(year), int(month), int(day))\n",
    "\n",
    "\n",
    "def fit_00_date_vs_range(d, date_range):\n",
    "    year, month, day = d.split(\"-\")  # pattern YYYY-MM-DD ensured here\n",
    "\n",
    "    msg = \"Date '\" + d + \"' out of accepted range! ('\" + \"' to '\".join(date_range) + \"')\"\n",
    "    if int(month) * int(day):  # both values are unequal zero - fully python-valid date format\n",
    "        if not calculate_date_object(date_range[0]) <= calculate_date_object(d) <= calculate_date_object(date_range[1]):\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            return False\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "    # day and/or month are zero'd - check year match first\n",
    "    if not int(date_range[0][0:4]) <= int(year) <= int(date_range[1][0:4]):\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "\n",
    "    if not int(month):\n",
    "        month_min = \"12\"\n",
    "        month_max = \"01\"\n",
    "    else:\n",
    "        month_min = month_max = month\n",
    "\n",
    "    if not int(day):\n",
    "        date_min = year + \"-\" + month_min + \"-\" + str(calendar.monthrange(int(year), int(month_max))[1]).zfill(2)\n",
    "        date_max = year + \"-\" + month_max + \"-01\"\n",
    "    else:\n",
    "        date_min = year + \"-\" + month_min + \"-\" + day\n",
    "        date_max = year + \"-\" + month_max + \"-\" + day\n",
    "\n",
    "    if calculate_date_object(date_range[0]) <= calculate_date_object(date_min):\n",
    "        if calculate_date_object(date_max) <= calculate_date_object(date_range[1]):\n",
    "            return d\n",
    "\n",
    "    throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "    return False\n",
    "\n",
    "\n",
    "# date: central access\n",
    "def check_date(d, sanitize=False, date_range=date_range_global):\n",
    "    # expected pattern: YYYY-MM-DD\n",
    "\n",
    "    # sanitize?\n",
    "    if sanitize:\n",
    "        d = sanitize_date(d)\n",
    "        if not d: return False\n",
    "\n",
    "    # test character set\n",
    "    if not re.compile(\"^(\\d+(?:-\\d+)*)$\").match(d):\n",
    "        msg = \"Illegal characters in date detected.\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "\n",
    "    # check pattern\n",
    "    d = check_date_pattern(d, sanitize)\n",
    "    if not d: return False\n",
    "\n",
    "    # check plausible ranges\n",
    "    year, month, day = d.split(\"-\")\n",
    "    if not 0 <= int(day) <= 31:\n",
    "        msg = \"Invalid day value (\" + str(day) + \")!\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        d = False\n",
    "    if not 0 <= int(month) <= 12:\n",
    "        msg = \"Invalid month value (\" + str(month) + \")!\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        d = False\n",
    "\n",
    "    if d: d = fit_00_date_vs_range(d, date_range)\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "def check_date_array_and_sanitize(str_date):\n",
    "    elements = [r.strip() for r in str_date.split(\",\")]\n",
    "    # corrected = []\n",
    "    error_flag = False\n",
    "    for i in range(len(elements)):\n",
    "        x = elements[i].split(\":\")\n",
    "        if len(x) > 2:\n",
    "            return False\n",
    "        try:\n",
    "            tmp = [str(f) for f in [check_date(x[j], date_range=date_range_global, sanitize=True) if x[j] else \"\" for j in range(len(x))]]\n",
    "            if calculate_date_object(tmp[0]) > calculate_date_object(tmp[1]):\n",
    "                msg = \"'\" + str_date + \"' => 'from' date greater than 'to' date in date range!\"\n",
    "                throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "                error_flag = True\n",
    "            elements[i] = \":\".join(tmp)\n",
    "        except ValueError:\n",
    "            return False\n",
    "    if error_flag:\n",
    "        return False\n",
    "    return \",\".join(elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sheet(sheet):\n",
    "\n",
    "    # Check header (sequence of expected columns might differ)\n",
    "    indices = get_header_indices(sheet.colnames, colname_map[sheet_name])\n",
    "    if not indices:\n",
    "        msg = \"Corrupt header line for '\" + sheet_name + \"' - please check log for details.\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "\n",
    "    # Remove unused COLUMNS\n",
    "    delete_columns = [i for i in range(sheet.number_of_columns()) if not sheet.colnames[i] in indices]\n",
    "    column_mapper = [i for i in range(sheet.number_of_columns()) if i not in delete_columns]\n",
    "    sheet.delete_columns(delete_columns)\n",
    "\n",
    "    # Index ROWS with Active = FALSE, if given\n",
    "    inactive_rows = []\n",
    "    if \"Active\" in sheet.colnames:\n",
    "        active_col = sheet.column[\"Active\"]\n",
    "        inactive_rows = [i for i in range(sheet.number_of_rows()) if active_col[i] in [0] + false_replacements]\n",
    "\n",
    "    # Index blank ROWS\n",
    "    blank_rows = [i for i in range(sheet.number_of_rows()) if blank_row(i, sheet.row[i])]\n",
    "\n",
    "    # Remove blank and inactive ROWS from sheet\n",
    "    # ToDo: report inactive lines as infos, blank lines as warnings\n",
    "    delete_rows = inactive_rows + blank_rows  # no overlap of lists possible...\n",
    "    row_mapper = [i for i in range(sheet.number_of_rows()) if i not in delete_rows]\n",
    "    sheet.delete_rows(delete_rows)\n",
    "\n",
    "    return sheet, row_mapper, column_mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column for compliance with model's respective field\n",
    "def check_regular_field_compliance(colname, sheet, model, fault_collector):\n",
    "    col = sheet.column[colname]\n",
    "    field = model._meta.get_field(colname)\n",
    "    bool_fields = get_bool_fields(model)\n",
    "    char_fields = get_char_fields(model)\n",
    "\n",
    "    ## general: blank AND blank allowed?\n",
    "    if not (field.blank and field.null) and field._get_default() is None:\n",
    "        fault_collector[colname][\"blank\"] = [i for i in range(len(col)) if col[i] == \"\"]\n",
    "\n",
    "    ## boolean fields: convertable?\n",
    "    if colname in bool_fields:\n",
    "        msg_base = \"Column '\" + colname + \"' expected to be either TRUE or FALSE - \"\n",
    "        colset = set([str(y) for y in col])\n",
    "        diff = colset.difference([\"0\", \"1\"])\n",
    "        if diff:  # contents not read from regular Excel bool cells - try adequate values\n",
    "            throw_or_enqueue(\"warning\", msg_base + \"found '\" + \"', '\".join(diff) + \"'\", main_msg_queue)\n",
    "            replaced_true = [1 if x in true_replacements else x for x in col]\n",
    "            replaced_false = [0 if x in false_replacements else x for x in replaced_true]\n",
    "            diff_again = set(replaced_false).difference([\"0\", \"1\"])\n",
    "            if diff_again:  # replacement failed - refuse\n",
    "                throw_or_enqueue(\"error\", msg_base + \"could not sanitize value(s) '\" + \"', '\".join(diff) + \"'\", main_msg_queue)\n",
    "                fault_collector[colname][\"bools\"] = [i for i in range(len(replaced_false)) if\n",
    "                                                           replaced_false[i] in diff_again]\n",
    "            else:  # replacement successful - exchange column\n",
    "                sheet.column[colname] = replaced_false\n",
    "\n",
    "    ## choices fields: in scope?\n",
    "    choices = field.choices\n",
    "    if choices:\n",
    "        fault_collector[colname][\"choices\"] = [i for i in range(len(col)) if\n",
    "                                                     col[i] not in [t[0] for t in choices]]\n",
    "        if fault_collector[colname][\"choices\"]:\n",
    "            fields = \"\\n  \".join([entry[0] + \": \" + entry[1] for entry in field.choices])\n",
    "            throw_or_enqueue(\"error\", \"Values for column '\" + colname + \"' exceed range of allowed choices:\\n\" + fields, main_msg_queue)\n",
    "            \n",
    "    ## character fields: length?\n",
    "    if colname in char_fields:\n",
    "        flag = False\n",
    "        for i in range(len(col)):\n",
    "            if col[i].__class__.__name__ != \"str\":\n",
    "                col[i] = str(col[i])\n",
    "                flag = True\n",
    "        if flag:\n",
    "            sheet.column[colname] = col\n",
    "        fault_collector[colname][\"length\"] = [i for i in range(len(col)) if len(col[i]) > field.max_length]\n",
    "        if fault_collector[colname][\"length\"]:\n",
    "            msg = \"Values for column '\" + colname + \"' exceed maximum string length of \" + field.max_length\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column for uniqueness, if required by model's respective field\n",
    "def check_uniqueness_for_column(colname, sheet, model, fault_collector):\n",
    "    if colname == model._meta.pk.name or model._meta.get_field(colname)._unique:\n",
    "        # check duplicates locally in column\n",
    "        col = sheet.column[colname]\n",
    "        c = Counter(col)\n",
    "        duplicates = [item for item in c.keys() if c[item] > 1]\n",
    "        fault_collector[colname][\"duplicate\"] = [i for i in range(len(col)) if col[i] in duplicates]\n",
    "        if fault_collector[colname][\"duplicate\"]:\n",
    "            msg = \"Found duplicate entries in column '\" + colname + \"' (unique required)\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        # check versus existing DB objects\n",
    "        existing = model.objects.values_list(colname, flat=True)\n",
    "        fault_collector[colname][\"assigned\"] = [i for i in range(len(col)) if col[i] in existing]\n",
    "        if fault_collector[colname][\"assigned\"]:\n",
    "            msg = \"Found entries in column '\" + colname + \"' already assigned in database (unique required).\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests, whether declarations of (type-dependent) domains are correct\n",
    "def check_domain(colname, sheet, codes, fault_collector):\n",
    "    # get rid off useless blanks and (allowed) brackets\n",
    "    col = [cell.strip(\" []\") for cell in sheet.column[colname]]\n",
    "    if not col == sheet.column[colname]:\n",
    "        sheet.column[colname] = col\n",
    "        msg = \"Removed useless leading/trailing whitespace characters from column '\" + colname + \"'\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "    datatypes = sheet.column[\"Datatype\"]\n",
    "    fault_collector[colname][\"domain\"] = []\n",
    "    db_codes = list(DatamodelCode.objects.values_list(\"Code\", flat=True))\n",
    "    all_codes = db_codes + codes\n",
    "\n",
    "    for i in range(len(col)):\n",
    "        if not len(col[i]):\n",
    "            continue  # Domain is optional... if empty: skip\n",
    "\n",
    "        # integer tests\n",
    "        if datatypes[i] in [\"int\", \"array(int)\"]:\n",
    "            corr = check_int_array_and_sanitize(col[i])\n",
    "            if corr:\n",
    "                if not col[i] == corr:\n",
    "                    msg = \"Found float values or whitespace chars in domain declaration of an integer-type variable.\"\n",
    "                    throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "                    col[i] = corr\n",
    "            else:\n",
    "                fault_collector[colname][\"domain\"].append(i)\n",
    "            continue\n",
    "\n",
    "        # float tests\n",
    "        if datatypes[i] in [\"float\", \"array(float)\"]:\n",
    "            corr = check_float_array_and_sanitize(col[i])\n",
    "            if corr:\n",
    "                if not col[i] == corr:\n",
    "                    msg = \"Found integer values or whitespace chars in domain declaration of a float-type variable: '\" + col[i] + \"'\"\n",
    "                    throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "                    col[i] = corr\n",
    "            else:\n",
    "                fault_collector[colname][\"domain\"].append(i)\n",
    "            continue\n",
    "\n",
    "        # code tests\n",
    "        if datatypes[i] in [\"code\", \"array(code)\"]:\n",
    "            corr = [r.strip() for r in col[i].split(\",\")]\n",
    "            if not \",\".join(corr) == col[i]:\n",
    "                msg = \"Removed unnecessary whitespaces in codes list.\"\n",
    "                throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "                col[i] = corr\n",
    "            misfits = [r for r in col[i].split(\",\") if r not in all_codes]\n",
    "            if misfits: \n",
    "                msg = \"Found unknown codes: \" + \", \".join(misfits)\n",
    "                throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "                fault_collector[colname][\"domain\"].append(i)\n",
    "            continue\n",
    "\n",
    "        # date tests\n",
    "        if datatypes[i] in [\"date\", \"array(date)\"]:\n",
    "            corr = check_date_array_and_sanitize(col[i])\n",
    "            if corr:\n",
    "                if not col[i] == corr:\n",
    "                    msg = \"Found sub-optimal formatting in domain declaration of a date-type variable.\"\n",
    "                    throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "                    col[i] = corr\n",
    "            else:\n",
    "                fault_collector[colname][\"domain\"].append(i)\n",
    "            continue\n",
    "\n",
    "    # if datatypes[i] == \"string\" and not array_float_array_pattern.match(col[i]):\n",
    "    if not col == sheet.column[colname]:\n",
    "        sheet.column[colname] = col\n",
    "        msg = \"Sanitized entries in column '\" + colname + \"'\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of empty sheet rows\n",
    "def blank_row(row_index, row):\n",
    "    result = [element for element in row if element != '']\n",
    "    return len(result) == 0\n",
    "\n",
    "\n",
    "# helper; determines whether issues have been recorded\n",
    "def get_error_flag(fault_collector, colname):\n",
    "    if [error for error in fault_collector[colname].keys() if fault_collector[colname][error]]:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check foreign key columns: string referencing correct (existing) key?\n",
    "def check_foreign_keys(colname, sheet, model, local_fault_collector, data_collector):\n",
    "    relations = get_relations(model)\n",
    "    if colname in [r.name for r in relations]:\n",
    "        # database entries: simple query on related model instances\n",
    "        pos = [r.name for r in relations].index(colname)\n",
    "        distmodel = relations[pos].related_model\n",
    "        distfield = relations[pos].to_fields[0]\n",
    "        db_keys = list(distmodel.objects.values_list(distfield, flat=True))\n",
    "\n",
    "        # sheet entries (for dependency levels > 1)\n",
    "        # extract from data collector; browse previously stored, lower dependency level sheets\n",
    "        sheet_keys = []\n",
    "        distmodel_name = distmodel._meta.model.__name__.lower()\n",
    "        if distmodel_name in data_collector:\n",
    "            colpos = data_collector[distmodel_name].colnames.index(distfield)\n",
    "            sheet_keys.extend([row[colpos] for row in data_collector[distmodel_name]])\n",
    "        \n",
    "        col = sheet.column[colname]\n",
    "        all_keys = set(db_keys + sheet_keys)\n",
    "        #print(db_keys)\n",
    "        #print(sheet_keys)\n",
    "        #print(all_keys)\n",
    "        if not set(col).issubset(all_keys):  # unknown foreign key referenced\n",
    "            local_fault_collector[colname][\"foreignkey\"] = [i for i in range(len(col)) if col[i] not in all_keys]\n",
    "            for i in local_fault_collector[colname][\"foreignkey\"]:\n",
    "                throw_or_enqueue(\"error\", \"Unknown target attribute referenced: '\" + col[i] + \"'\", main_msg_queue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup containers for sheet/model\n",
    "def fill_import_containers(importer, data_collector, model, sheet):\n",
    "    # generate import adapter from model\n",
    "    adapter = DjangoModelImportAdapter(model)\n",
    "    # print(sheet.colnames)\n",
    "    apter.column_names = sheet.colnames\n",
    "    \n",
    "    # add adapter to importer (= queue for current dependency level)\n",
    "    importer.append(adapter)\n",
    "\n",
    "    # feed data collector struct with sheet-derived data\n",
    "    # data_collector[adapter.get_name()] = sheet.get_internal_array()\n",
    "    data_collector[adapter.get_name()] = sheet\n",
    "    print(data_collector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# float\n",
    "def floatable(x, sanitize=False):\n",
    "    if sanitize:\n",
    "        value = x.replace(\",\", \".\")\n",
    "        if value != x:\n",
    "            throw_or_enqueue(\"warning\", \"Converted floating point symbol in '\" + x + \"' (German notation ',' found!).\", main_msg_queue)\n",
    "            x = value\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "# float\n",
    "def advanced_string2float(string, refU_obj, verified_UCUM_units={}, value_conversions={}):\n",
    "    string = consider_unit_and_convert(string, refU_obj, verified_UCUM_units, value_conversions)\n",
    "    num = floatable(value)\n",
    "    if not num:\n",
    "        throw_or_enqueue(\"error\", \"Could not convert value to integer number: '\" + string, main_msg_queue)\n",
    "    return num\n",
    "\n",
    "\n",
    "# code\n",
    "def check_codekey_matches(values, target_code, sanitize=False):\n",
    "    target_keys = set(DatamodelCode.objects.filter(Code=target_code).values_list(\"Key\", flat=True))\n",
    "    if not target_keys:\n",
    "        throw_or_enqueue(\"error\", \"Could not find code system '\" + target_code + \"'\", main_msg_queue)\n",
    "        return False\n",
    "    try:\n",
    "        diff = set(values).difference(target_keys)\n",
    "    except KeyError:\n",
    "        diff = True\n",
    "    if diff:\n",
    "        if sanitize:\n",
    "            fail = []\n",
    "            success = []\n",
    "            sanitized = []\n",
    "            for item in list(values):\n",
    "                try_hard = str(advanced_string2int(item))\n",
    "                if try_hard in target_keys:\n",
    "                    success.append(try_hard)\n",
    "                    if item != try_hard:\n",
    "                        sanitized.append(item)\n",
    "                else:\n",
    "                    fail.append(item)\n",
    "            if fail:\n",
    "                msg = \"Found key(s) '\" + \", \".join(fail) + \"' being incompatible to code system '\"\\\n",
    "                      + target_code + \"' (not in [\" + \", \".join(sorted(target_keys)) + \"])\"\n",
    "                throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "                return False\n",
    "            msg = \"Key(s) '\" + \", \".join(sanitized) + \"' had to be sanitized in order to be compatible to code system '\"\\\n",
    "                  + target_code + \"'\"\n",
    "            throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "            return values.__class__(success)\n",
    "        msg = \"Found key(s) '\" + \", \".join(values) + \"' being incompatible to code system '\"\\\n",
    "              + target_code + \"' (not in [\" + \", \".join(sorted(target_keys)) + \"])\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "    return values\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def consider_unit_and_convert(var, refU_obj, verified={}, conversions={}):\n",
    "    value, unit = separate_value_and_unit(var)\n",
    "\n",
    "    if not value:  # errornous outputs\n",
    "        return False\n",
    "\n",
    "    if not unit:  # no unit detected, keep value as is\n",
    "        return value\n",
    "\n",
    "    refU = refU_obj.Unit\n",
    "\n",
    "    # check if reference or not (yes = no action required)\n",
    "    if unit == refU:\n",
    "        return value\n",
    "\n",
    "    if refU_obj.UCUM:  # verify UCUM membership (automated conversion is yet possible for those only!)\n",
    "        return convert_using_UCUM(value, unit, refU, verified, conversions)\n",
    "    else:\n",
    "        throw_or_enqueue(\"error\", \"Auto-conversion from '\" + unit + \"' to '\" + refU\\\n",
    "                         + \"' unavailable (no UCUM units).)\", main_msg_queue)\n",
    "        return False\n",
    "\n",
    "\n",
    "# integer\n",
    "def represents_int(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "    \n",
    "# integer\n",
    "def lossless_float2int(numstring):\n",
    "    if numstring.count(\".\") == 1:\n",
    "        integer, decimal = numstring.split(\".\")\n",
    "        if represents_int(integer):\n",
    "            if not decimal or (represents_int(decimal) and int(decimal) == 0):\n",
    "                throw_or_enqueue(\"warning\", \"Converted '\" + numstring + \"' to integer '\" + integer + \"' (lossless)\", main_msg_queue)\n",
    "                return integer\n",
    "    throw_or_enqueue(\"error\", \"Could not convert float value to integer number: \" + numstring, main_msg_queue)\n",
    "    return False\n",
    "\n",
    "\n",
    "# integer\n",
    "def advanced_string2int(string, refU_obj=None, verified_UCUM_units={}, value_conversions={}):\n",
    "    if \",\" in string:\n",
    "        string = string.replace(\",\", \".\")\n",
    "        throw_or_enqueue(\"error\", \"Converted '\" + string + \"' to international decimal '.'!\", main_msg_queue)\n",
    "\n",
    "    if \".\" in string:\n",
    "        string = lossless_float2int(string)\n",
    "        if not string:\n",
    "            throw_or_enqueue(\"error\", \"Could not convert value to integer number: \" + string, main_msg_queue)\n",
    "            return False\n",
    "\n",
    "    if refU_obj and not refU_obj.Unit == \"None\":\n",
    "        string = consider_unit_and_convert(string, refU_obj, verified_UCUM_units, value_conversions)\n",
    "        if not string:\n",
    "            throw_or_enqueue(\"error\", \"Could not convert value to integer number: \" + string, main_msg_queue)\n",
    "            return False\n",
    "\n",
    "    try:\n",
    "        return int(string)\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "# num (both integer and float)\n",
    "def check_num_domain_fit(var_num, domain, type):\n",
    "    for subdomain in array_from_string(domain):\n",
    "        leftfit = rightfit = True\n",
    "        left, right = array_from_string(subdomain, delim=\":\", convert=type)\n",
    "        if left and var_num < left:\n",
    "            leftfit = False\n",
    "        if right and var_num > right:\n",
    "            rightfit = False\n",
    "        if leftfit and rightfit:\n",
    "            return var_num\n",
    "    throw_or_enqueue(\"error\", \"'\" + str(var_num) + \"' exceeds value range of defined domain: \" + str(domain), main_msg_queue)\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement contents... and call in data import's main()\n",
    "def apply_transformation(var_int, transformation):\n",
    "    return var_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date\n",
    "def check_date_domain_fit(var_date, domain):\n",
    "    # domain = two-item array of dates\n",
    "    if domain[0] and var_date < domain[0]:\n",
    "        throw_or_enqueue(\"error\", \"'\" + str(var_date) + \"' exceeds date range: < \" + str(domain[0]), main_msg_queue)\n",
    "        return False\n",
    "    if domain[1] and var_date > domain[1]:\n",
    "        throw_or_enqueue(\"error\", \"'\" + str(var_date) + \"' exceeds date range: > \" + str(domain[1]), main_msg_queue)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# array of elements from formatted string\n",
    "def array_from_string(instring, delim=\",\", convert=\"string\"):\n",
    "    #cont = (instring.split(\"[\"))[1].split(\"]\")[0]\n",
    "    if convert == \"int\":\n",
    "        return [int(x) for x in instring.split(delim)]\n",
    "    elif convert == \"float\":\n",
    "        return [float(x) for x in instring.split(delim)]\n",
    "    elif convert == \"string\":\n",
    "        return instring.split(delim)\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# two-item array of elements ('domain' as from/to pairing)\n",
    "def domain_from_string(instring, generic_from=False, generic_to=False):\n",
    "    fr, to = array_from_string(instring)\n",
    "    if not fr and generic_from: fr = generic_from\n",
    "    if not to and generic_to: to = generic_to\n",
    "    return fr, to\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def separate_value_and_unit(var):\n",
    "    var = re.sub(r\"\\s\", \"\", var)\n",
    "    value = \"\".join(re.findall(r\"[\\d.]\", var))\n",
    "    try:\n",
    "        startpos = var.index(value)\n",
    "        if startpos == 0:\n",
    "            unit = var[(len(value)):]\n",
    "            return value, unit\n",
    "        else:\n",
    "            return False, False\n",
    "    except ValueError as e:\n",
    "        msg = \"No valid number, even considering trailing unit declarations: \" + var\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False, False\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def UCUM_server_reply2dict(reply):\n",
    "    d = dict()\n",
    "    for r in reply:\n",
    "        u, v = r.split(\" = \")\n",
    "        if v == \"true\":\n",
    "            d[u] = True\n",
    "        elif v == \"false\":\n",
    "            d[u] = False\n",
    "        else:\n",
    "            d[u] = v\n",
    "    return d\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def verify_units2UCUM(actual_unit, reference_unit, buffer_dict={}):\n",
    "    call = [x for x in [actual_unit, reference_unit] if x not in buffer_dict]\n",
    "    if not call:\n",
    "        return {}\n",
    "    reply = ucumVerify(call, ucum_api_url)\n",
    "    reply_dict = UCUM_server_reply2dict(reply)\n",
    "    if not reference_unit in buffer_dict and not reference_unit in reply_dict:\n",
    "        throw_or_enqueue(\"error\", \"Could not resolve reference unit in UCUM!\", main_msg_queue)\n",
    "        return False\n",
    "    elif actual_unit in buffer_dict and not actual_unit in reply_dict:\n",
    "        throw_or_enqueue(\"error\", \"Could not resolve reference unit in UCUM!\", main_msg_queue)\n",
    "        return False\n",
    "    else:\n",
    "        return reply_dict\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def generate_conversion_api_urls(actual_unit, reference_unit, value=1):\n",
    "    collector = {}\n",
    "    if isinstance(actual_unit, list) or isinstance(reference_unit, list):\n",
    "        if len(actual_unit) != len(reference_unit):\n",
    "            return False\n",
    "        else:\n",
    "            for i in range(0, len(actual_unit)):\n",
    "                collector.update(generate_conversion_api_urls(actual_unit[i], reference_unit[i]))\n",
    "    else:\n",
    "        url = ucum_api_url + \"/ucumtransform\"\n",
    "        request = url + \"/\" + str(value) + \"/from/\" + actual_unit + \"/to/\" + reference_unit\n",
    "        request.replace(\"//\", \"/\")\n",
    "        collector[actual_unit + \"=>\" + reference_unit] = request\n",
    "    return collector\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def get_responses_from_UCUM(actU, refU, value):\n",
    "    urls = generate_conversion_api_urls(actU, refU, value)\n",
    "    responses = {}\n",
    "    for conv in urls.keys():\n",
    "        # request = urls['g/l=>g/dL']\n",
    "        request = urls[conv]\n",
    "        try:\n",
    "            with urllib.request.urlopen(request) as res:\n",
    "                context = ET.fromstring(res.read())\n",
    "                # print(context)\n",
    "                for child in context:\n",
    "                    tmp1 = {}\n",
    "                    if child.text == None:\n",
    "                        for element in child:\n",
    "                            # print(element.tag)\n",
    "                            tmp1[element.tag] = element.text\n",
    "                            # print(child, tmp1)\n",
    "                    elif child.text != None:  # error handling ERROR: unexpected result: Invalid UCUM Transformation Expression\n",
    "                        # print(child.text)\n",
    "                        tmp1[\"ERROR\"] = child.text\n",
    "        except urllib.error.HTTPError as e:  # error handling bad request\n",
    "            tmp1[\"ERROR\"] = e\n",
    "        responses[conv] = tmp1\n",
    "    return responses\n",
    "\n",
    "\n",
    "# num + unit\n",
    "def convert_using_UCUM(value, actU, refU, verified={}, conversions={}):\n",
    "    reply = verify_units2UCUM(actU, refU, verified)\n",
    "    if reply is False:\n",
    "        return False\n",
    "    verified.update(reply)\n",
    "\n",
    "    # conversion (for UCUM units)\n",
    "    try:\n",
    "        if verified[actU] and verified[refU]:\n",
    "            conv = actU + \"=>\" + refU\n",
    "            rev_conv = refU + \"=>\" + actU\n",
    "            if conv in conversions:\n",
    "                # use 'conversions' dict for calculating the VALUE according to the reference UNIT\n",
    "                value = str(float(value) * conversions[conv])\n",
    "            elif rev_conv in conversions:\n",
    "                # reverse available conversion\n",
    "                value = str(float(value) / conversions[rev_conv])\n",
    "            else:\n",
    "                # query UCUM server API for factor\n",
    "                responses = get_responses_from_UCUM(actU, refU, value)\n",
    "                value = responses[conv]['ResultQuantity']\n",
    "                factor = float(responses[conv]['ResultQuantity']) / float(responses[conv]['SourceQuantity'])\n",
    "                conversions[conv] = factor\n",
    "            return value\n",
    "        else:\n",
    "            msg = \"Auto-conversion from '\" + actU + \"' to '\" + refU + \"' unavailable (could not verify using UCUM server).\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "    except KeyError as e:\n",
    "        throw_or_enqueue(\"error\", \"An error occured while trying to convert a UCUM unit...\", main_msg_queue)\n",
    "\n",
    "    return False\n",
    "\n",
    "#convert_using_UCUM(\"2\", \"d\", \"s\")   # True\n",
    "#convert_using_UCUM(\"2\", \"x\", \"s\")   # False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general entry point for deep tests on all available data types\n",
    "# TODO: test transformations\n",
    "# TODO: in data main(), transform input values into target space by source (no mapping/source information necessary to hand in here)\n",
    "def ensure_datatype_and_domain_fit(values, target, transformation=False, date_range=date_range_global,\n",
    "                                   sanitize=False, verified_UCUM_units={}, value_conversions={}):\n",
    "    sanitized = False\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        var = values[i]\n",
    "        c = list()\n",
    "\n",
    "        if target.Datatype in [\"int\", \"array(int)\"]:\n",
    "            for v in array_from_string(var):\n",
    "                try:\n",
    "                    var_int = int(v)\n",
    "                except ValueError:\n",
    "                    if sanitize:\n",
    "                        var_int = advanced_string2int(v, target.Unit, verified_UCUM_units, value_conversions)\n",
    "                        sanitized = True\n",
    "                    else:\n",
    "                        throw_or_enqueue(\"error\", \"Could not convert value to integer number: \" + v, main_msg_queue)\n",
    "                        var_int = False\n",
    "                if var_int and transformation:\n",
    "                    var_int = apply_transformation(var_int, transformation)\n",
    "                if var_int and target.Domain:\n",
    "                    var_int = check_num_domain_fit(var_int, target.Domain, \"int\")\n",
    "                if var_int:\n",
    "                    c.append(str(var_int))\n",
    "                else:\n",
    "                    c.append(var_int)\n",
    "\n",
    "        elif target.Datatype in [\"float\", \"array(float)\"]:\n",
    "            for v in array_from_string(var):\n",
    "                try:\n",
    "                    var_float = float(v)\n",
    "                    if not str(var_float) == v:\n",
    "                        sanitized = True\n",
    "                        msg = \"Found integer number ('\" + v + \"') where float expected\"\n",
    "                        if not sanitize:\n",
    "                            var_float = False\n",
    "                            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "                        else:\n",
    "                            throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "                except ValueError:\n",
    "                    if sanitize:\n",
    "                        var_float = advanced_string2float(var, target.Unit, verified_UCUM_units, value_conversions)\n",
    "                        sanitized = True\n",
    "                    else:\n",
    "                        throw_or_enqueue(\"error\", \"Could not convert value to float number: \" + var, main_msg_queue)\n",
    "                        var_float = False\n",
    "                if var_float and transformation:\n",
    "                    var_float = apply_transformation(var_float, transformation)\n",
    "                if var_float and target.Domain:\n",
    "                    var_float = check_num_domain_fit(var_float, target.Domain, \"float\")\n",
    "                if var_float:\n",
    "                    c.append(str(var_float))\n",
    "                else:\n",
    "                    c.append(var_float)\n",
    "\n",
    "        elif target.Datatype in [\"date\", \"array(date)\"]:\n",
    "            if target.Domain:\n",
    "                ddomain = [datetime.strptime(x, '%Y-%m-%d') if x else False for x in domain_from_string(target.Domain)]\n",
    "            for v in array_from_string(var):\n",
    "                v_ = check_date(v, date_range=date_range, sanitize=sanitize)\n",
    "                if v_:\n",
    "                    if v != v:\n",
    "                        throw_or_enqueue(\"warning\", \"Had to sanitize date statement: \" + v + \" => \" + v_, main_msg_queue)\n",
    "                        v = v_\n",
    "                    if target.Domain and not check_date_domain_fit(datetime.strptime(v, '%Y-%m-%d'), ddomain):\n",
    "                        v = False\n",
    "                else:\n",
    "                    v = False\n",
    "                if v:\n",
    "                    c.append(str(v))\n",
    "                else:\n",
    "                    c.append(v)\n",
    "\n",
    "        elif target.Datatype in [\"code\", \"array(code)\"]:\n",
    "            #key_map = {m.Source_Value: m.Target_Equivalent for m in\n",
    "            #           DatamodelCodeMapping.objects.filter(Code_Mapping=target.Transformation)}\n",
    "            for v in array_from_string(var):\n",
    "                v_ = check_codekey_matches(v, target.Domain, sanitize=sanitize)\n",
    "                if v_:\n",
    "                    if v != v:\n",
    "                        throw_or_enqueue(\"warning\", \"Had to sanitize code key: \" + v + \" => \" + v_, main_msg_queue)\n",
    "                        v = v_\n",
    "                else:\n",
    "                    v = False\n",
    "                if v:\n",
    "                    c.append(str(v))\n",
    "                else:\n",
    "                    c.append(v)\n",
    "\n",
    "        else:\n",
    "            throw_or_enqueue(\"error\", \"Test for data model variable type '\" + target.Datatype + \"' is not implemented.\", main_msg_queue)\n",
    "            c.append(False)\n",
    "\n",
    "        if False not in c:\n",
    "            values[i] = \",\".join(c)\n",
    "        else:\n",
    "            values[i] = False\n",
    "\n",
    "    if False in values:\n",
    "        return False, sanitized\n",
    "    \n",
    "    return values, sanitized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_formula(t, restrict=[]):      # 'pattern' parameter for development only!\n",
    "    functions = [\"FORMULA\", \"MEAN\", \"RANK\", \"SUM\", \"DELTA\", \"DIV\", \"PROD\", \"DRANGE\", \"DATE\"]\n",
    "    operators = [\"+\", \"-\", \"/\", \"*\", \"%\", \"^\"] #, \"(\", \")\"]\n",
    "    \n",
    "    left_bracket = False\n",
    "    right_bracket = False\n",
    "    #print(\"==> '\" + t + \"'\")\n",
    "    r = t.strip()\n",
    "    if not r == t:\n",
    "        t = r\n",
    "        throw_or_enqueue(\"warning\", \"Removed leading/trailing whitespaces from formula.\", main_msg_queue)\n",
    "    \n",
    "    error_flag = False\n",
    "    try:\n",
    "        left_bracket = t.index(\"(\")\n",
    "    except ValueError:\n",
    "        error_flag = True\n",
    "        throw_or_enqueue(\"error\", \"No opening bracket in formula.\", main_msg_queue)\n",
    "    try:\n",
    "        right_bracket = t.rindex(\")\")\n",
    "    except ValueError:\n",
    "        error_flag = True\n",
    "        throw_or_enqueue(\"error\", \"No closing bracket in formula.\", main_msg_queue)\n",
    "    \n",
    "    if not right_bracket == len(t) - 1:\n",
    "        error_flag = True\n",
    "        throw_or_enqueue(\"error\", \"Formula declaration does not end with closing bracket.\", main_msg_queue)\n",
    "    function = t[:left_bracket]\n",
    "    if not function in functions:\n",
    "        error_flag = True\n",
    "        if not function:\n",
    "            msg = \"Formula declaration does not start with any function call.\"\n",
    "        else:\n",
    "            msg = \"Formula declaration does not start with any known function call - found '\" + function + \"'...\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "    \n",
    "    if error_flag:\n",
    "        msg = \"Could not parse a valid formula following scheme 'FUNCTION(parameters | math expr.)'', with FUNCTION out of \" \\\n",
    "               + \"['\" + \"', '\".join(functions) + \"']\" + \".\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "    \n",
    "    inner = t[left_bracket+1:right_bracket]\n",
    "    if function == \"FORMULA\":\n",
    "        delim = \" \"\n",
    "        pattern = \" (?![^()]*\\))\"\n",
    "    else:\n",
    "        delim = \", \"\n",
    "        pattern = \"[,](?![^()]*\\))\"\n",
    "    elements = [x.strip() for x in re.split(r''+pattern, inner) if x]\n",
    "    \n",
    "    refactored = []\n",
    "    for e in elements:\n",
    "        c = []\n",
    "        for ci in range(len(e)):\n",
    "            if e[ci] in operators:\n",
    "                c.append(ci)\n",
    "        if c:\n",
    "            first = e[:c[0]].strip()\n",
    "            if first:\n",
    "                refactored.append(first)\n",
    "            for j in range(len(c)-1):\n",
    "                refactored.append(e[c[j]].strip())\n",
    "                refactored.append(e[c[j]+1:c[j+1]].strip())\n",
    "            refactored.append(e[c[-1]].strip())\n",
    "            last = e[c[-1]+1:].strip()\n",
    "            if last:\n",
    "                refactored.append(last)\n",
    "        else:\n",
    "            refactored.append(e)\n",
    "    \n",
    "    #print(refactored)\n",
    "    \n",
    "    misfits = []\n",
    "    for ri in range(len(refactored)):\n",
    "        r = refactored[ri]\n",
    "        if not r:\n",
    "            continue\n",
    "        if r in operators:\n",
    "            continue\n",
    "        if floatable(r.strip(\"()\")):\n",
    "            continue\n",
    "        if \"(\" in r and r[:r.index(\"(\")] in functions:\n",
    "            ret = check_formula(r, restrict=restrict)\n",
    "            if ret:\n",
    "                if not r == ret:\n",
    "                    refactored[ri] = ret\n",
    "                continue\n",
    "            else:\n",
    "                misfits.append(r)\n",
    "                continue\n",
    "        elif restrict:\n",
    "            if not r.strip(\"()\") in restrict:\n",
    "                throw_or_enqueue(\"error\", \"Unknown element in formula declaration: '\" + r.strip(\"()\") + \"'\", main_msg_queue)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            value, unit = separate_value_and_unit(r.strip(\"()\"))\n",
    "            if value:\n",
    "                if not unit:\n",
    "                    continue\n",
    "                else:\n",
    "                    if convert_using_UCUM(value, unit, \"s\"):    # check for time tolerance parameter:\n",
    "                        continue                                #  try conversion to seconds (base unit)\n",
    "        if restrict:\n",
    "            misfits.append(r.strip(\"()\"))\n",
    "    \n",
    "    if misfits:\n",
    "        msg = \"Issues on formula elements : \" + \", \".join(misfits)\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        return False\n",
    "    \n",
    "    return t[:left_bracket] + \"(\" + delim.join([r for r in refactored if r]) + \")\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUM(SEX, DOB)', '*', '5']\n",
      "['SEX', 'DOB']\n",
      "FORMULA( SUM(SEX, DOB)* 5) ==> FORMULA(SUM(SEX, DOB) * 5)\n",
      "-----------------------------------------------------------------------\n",
      "['SUM(SEX, DOB)', '*', '5']\n",
      "['SEX', 'DOB']\n",
      "FORMULA( SUM(SEX, DOB)* 5) ==> FORMULA(SUM(SEX, DOB) * 5)\n",
      "=======================================================================\n",
      "['(BNT_SUM_Z', '-', '100)', '/', '10)']\n",
      "FORMULA( (BNT_SUM_Z - 100) / 10) ) ==> FORMULA((BNT_SUM_Z - 100) / 10))\n",
      "-----------------------------------------------------------------------\n",
      "['(BNT_SUM_Z', '-', '100)', '/', '10)']\n",
      "FORMULA( (BNT_SUM_Z - 100) / 10) ) ==> FORMULA((BNT_SUM_Z - 100) / 10))\n",
      "=======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Formula test setup (ignorieren...)\n",
    "db_attrs = set(DatamodelAttribute.objects.all().values_list(\"Attribute\", flat=True))\n",
    "f = []\n",
    "#f.append([\"FORMULA( SUM(adasgcty,adasgctn) *(5+1))\", \"FORMULA(SUM(adasgcty, adasgctn) * (5 + 1))\", False])\n",
    "f.append([\"FORMULA( SUM(SEX, DOB)* 5)\", \"FORMULA(SUM(SEX, DOB) * 5)\", \"FORMULA(SUM(SEX, DOB) * 5)\"])\n",
    "#f.append([\"MEAN( SEX, DOB)\", \"MEAN(SEX, DOB)\", \"MEAN(SEX, DOB)\"])\n",
    "f.append([\"FORMULA( (BNT_SUM_Z - 100) / 10) )\", \"FORMULA((BNT_SUM_Z - 100) / 10))\", \"FORMULA((BNT_SUM_Z - 100) / 10))\"])\n",
    "\n",
    "for f_ in f:\n",
    "    ret = check_formula(f_[0])\n",
    "    if not ret == f_[1]:\n",
    "        print(\"!!! \" + f_[0] + \" ==> \" + str(ret))\n",
    "    else:\n",
    "        print(f_[0] + \" ==> \" + str(ret))\n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    ret = check_formula(f_[0], restrict=db_attrs)\n",
    "    if not ret == f_[2]:\n",
    "        print(\"!!! \" + f_[0] + \" ==> \" + str(ret))\n",
    "    else:\n",
    "        print(f_[0] + \" ==> \" + str(ret))\n",
    "    print(\"=======================================================================\")\n",
    "    \n",
    "for msg in main_msg_queue:\n",
    "    print(msg)\n",
    "main_msg_queue = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_transformation(colname, sheet, fault_collector, source_code_mappings={}):\n",
    "    db_code_mappings = list(DatamodelCodeMapping.objects.values_list(\"Code_Mapping\", flat=True))\n",
    "    db_attrs = set(DatamodelAttribute.objects.all().values_list(\"Attribute\", flat=True))\n",
    "    source_attrs = set(sheet.column[\"Source_Attribute\"])\n",
    "    target_column = sheet.column[\"Target_Attribute\"]\n",
    "    fault_collector[colname][\"transformation\"] = []\n",
    "    #formulas = [\"FORMULA\", \"MEAN\", \"RANK\", \"SUM\", \"DELTA\", \"DIV\", \"PROD\", \"DRANGE\", \"DATE\"]\n",
    "    #operators = [\"+\", \"-\", \"/\", \"*\", \"%\", \"^\"]\n",
    "    #pattern = \",|\\s|\\d\" + \"|[(\" + ''.join(operators) + \")]\"\n",
    "    \n",
    "    col = [cell.strip() for cell in sheet.column[colname]]\n",
    "    if not col == sheet.column[colname]:\n",
    "        msg = \"Removed useless leading/trailing whitespace characters from column '\" + colname + \"'\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "    \n",
    "    for i in range(len(col)):\n",
    "        if not col[i]:  # transformation is optional...\n",
    "            continue\n",
    "        t = col[i]\n",
    "        # check, if the referenced code mapping is compatible to target variable's domain by values\n",
    "        if t in db_code_mappings:\n",
    "            #print(str(i) + \": \" + t + \" [CM]\")\n",
    "            cm_targeted_keys = list(set(DatamodelCodeMapping.objects.filter(Code_Mapping=t).values_list(\"Target_Equivalent\", flat=True)))\n",
    "        elif t in source_code_mappings:\n",
    "            #print(str(i) + \": \" + t + \" [cm]\")\n",
    "            cm_targeted_keys = sorted(source_code_mappings[t])\n",
    "        else:  # no code mapping found... should be a valid formula\n",
    "            #print(str(i) + \": \" + t + \" [PF]\")\n",
    "            corr = check_formula(t, restrict=list(db_attrs.union(source_attrs)))\n",
    "            #print( str(i) + \": \" + str(col[i]) + \" ==> \" + str(corr) )\n",
    "            if corr:\n",
    "                col[i] = corr\n",
    "            else:\n",
    "                fault_collector[colname][\"transformation\"].append(i)\n",
    "            continue\n",
    "        \n",
    "        # found a code mapping; value space acquired above\n",
    "        target_obj = DatamodelAttribute.objects.filter(Attribute=target_column[i])[0]\n",
    "        cm_targeted_keys_new, sanitized = ensure_datatype_and_domain_fit(cm_targeted_keys, target_obj)\n",
    "        \n",
    "        #cm_targeted_keys = check_codekey_matches(cm_targeted_keys, target_obj.Domain)\n",
    "        if not cm_targeted_keys_new:\n",
    "            msg = \"Could not apply code mapping '\" + t + \"'; mismatches targeted attribute '\" + target_obj.Attribute + \"'...\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            fault_collector[colname][\"transformation\"].append(i)\n",
    "        \n",
    "        sheet.column[colname] = col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_function(colname, sheet, fault_collector):\n",
    "    db_attrs = set(DatamodelAttribute.objects.all().values_list(\"Attribute\", flat=True))\n",
    "    source_attrs = set(sheet.column[\"Attribute\"])\n",
    "    #target_column = sheet.column[\"Target_Attribute\"]\n",
    "    fault_collector[colname][\"function\"] = []\n",
    "    #formulas = [\"FORMULA\", \"MEAN\", \"RANK\", \"SUM\", \"DELTA\", \"DIV\", \"PROD\", \"DRANGE\", \"DATE\"]\n",
    "    #operators = [\"+\", \"-\", \"/\", \"*\", \"%\", \"^\"]\n",
    "    #pattern = \",|\\s|\\d\" + \"|[(\" + ''.join(operators) + \")]\"\n",
    "    \n",
    "    col = [cell.strip() for cell in sheet.column[colname]]\n",
    "    if not col == sheet.column[colname]:\n",
    "        msg = \"Removed useless leading/trailing whitespace characters from column '\" + colname + \"'\"\n",
    "        throw_or_enqueue(\"warning\", msg, main_msg_queue)\n",
    "    \n",
    "    for i in range(len(col)):\n",
    "        corr = check_formula(col[i])\n",
    "        #print( str(i) + \": \" + str(col[i]) + \" ==> \" + str(corr) )\n",
    "        if corr:\n",
    "            col[i] = corr\n",
    "        else:\n",
    "            fault_collector[colname][\"function\"].append(i)\n",
    "        continue\n",
    "    \n",
    "    sheet.column[colname] = col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations(model):\n",
    "    return [f for f in model._meta.fields if f.is_relation]\n",
    "\n",
    "\n",
    "def foreign_key_replacement(target_model, target_colname, column, blank_allowed=False):  # toDo: enable reporting\n",
    "    i = 0\n",
    "    while i < len(column):\n",
    "        entry = column[i]\n",
    "        if not entry:\n",
    "            if not blank_allowed:\n",
    "                msg = \"Foreign Key field '\" + target_colname \\\n",
    "                + \"' could not be served (empty source file field in input line \" \\\n",
    "                + str(i + 2) + \")!\"\n",
    "                throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "                return False\n",
    "            column[i] = ''\n",
    "        else:\n",
    "            try:\n",
    "                targetObj = target_model.objects.filter(**{target_colname: entry})[0]\n",
    "            except IndexError:\n",
    "                msg = \"Foreign Key field '\" + target_colname \\\n",
    "                      + \"' could not be served (key '\" + entry \\\n",
    "                      + \"' could not be resolved)!\"\n",
    "                throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "                return False\n",
    "            column[i] = targetObj\n",
    "        i += 1\n",
    "    return column\n",
    "\n",
    "\n",
    "def setup_foreign_keys_in_sheet(sheet, model):\n",
    "    relations = get_relations(model)\n",
    "    i = 0\n",
    "    for colname in sheet.colnames:  # iterate over sheet-derived names\n",
    "        try:\n",
    "            fk_index = [r.name for r in relations].index(colname)\n",
    "            target_model = relations[fk_index].related_model\n",
    "            target_column = relations[fk_index].to_fields[0]\n",
    "            msg = \" --> Resolving Foreign Keys...\"\n",
    "            throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "            blank_allowed = relations[fk_index].blank and relations[fk_index].null\n",
    "            new_col = foreign_key_replacement(target_model, target_column, sheet.column[colname], blank_allowed)\n",
    "            if not new_col:\n",
    "                return False\n",
    "            sheet.column[colname] = new_col\n",
    "        except ValueError:\n",
    "            # regular_fields\n",
    "            pass\n",
    "        i += 1\n",
    "    return sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheet2model_core(sheet, model, data_collector, domain_extension=[]):\n",
    "    \n",
    "    error_flag = False\n",
    "    \n",
    "    sheet, row_mapper, column_mapper = prepare_sheet(sheet)\n",
    "    \n",
    "    # For all remaining data, check model compliance (by columns)\n",
    "    fault_collector = {}\n",
    "    msg = \"\\tWorking on columns:\"\n",
    "    throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "    for colname in colname_map[sheet_name]:\n",
    "        msg = \"\\t * \" + colname\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        fault_collector[colname] = {}\n",
    "\n",
    "        check_regular_field_compliance(colname, sheet, model, fault_collector)\n",
    "\n",
    "        check_uniqueness_for_column(colname, sheet, model, fault_collector)\n",
    "\n",
    "        if colname == \"Domain\":\n",
    "            check_domain(colname, sheet, domain_extension, fault_collector)\n",
    "\n",
    "        if not error_flag:\n",
    "            error_flag = get_error_flag(fault_collector, colname)\n",
    "\n",
    "        if not error_flag:\n",
    "            check_foreign_keys(colname, sheet, model, \n",
    "                               fault_collector, \n",
    "                               data_collector)\n",
    "        \n",
    "        if not error_flag:\n",
    "            error_flag = get_error_flag(fault_collector, colname)\n",
    "    # END OF LOOP over columns of sheet\n",
    "    \n",
    "    if not error_flag:  # prepare DB import of data IF no errors occurred yet\n",
    "        # generate import adapter from model\n",
    "        adapter = DjangoModelImportAdapter(model)\n",
    "        adapter.column_names = sheet.colnames\n",
    "        # feed data collector struct with sheet-derived data\n",
    "        data_collector[adapter.get_name()] = sheet\n",
    "        return adapter, fault_collector, row_mapper, column_mapper \n",
    "    return False, fault_collector, row_mapper, column_mapper \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sheet2model_mapping(sheet, model, data_collector, source_code_mappings={}):\n",
    "    \n",
    "    error_flag = False\n",
    "    \n",
    "    sheet, row_mapper, column_mapper = prepare_sheet(sheet)\n",
    "    \n",
    "    # For all remaining data, check model compliance (by columns)\n",
    "    fault_collector = {}\n",
    "    msg = \"\\tWorking on columns:\"\n",
    "    throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "    for colname in colname_map[sheet_name]:\n",
    "        msg = \"\\t * \" + colname\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        fault_collector[colname] = {}\n",
    "\n",
    "        check_regular_field_compliance(colname, sheet, model, fault_collector)\n",
    "\n",
    "        check_uniqueness_for_column(colname, sheet, model, fault_collector)\n",
    "\n",
    "        if colname == \"Transformation\":\n",
    "            check_transformation(colname, sheet, fault_collector,\n",
    "                                 source_code_mappings=source_code_mappings)\n",
    "        \n",
    "        if colname == \"Function\":\n",
    "            check_function(colname, sheet, fault_collector)\n",
    "\n",
    "        if not error_flag:\n",
    "            error_flag = get_error_flag(fault_collector, colname)\n",
    "\n",
    "        if not error_flag:\n",
    "            check_foreign_keys(colname, sheet, model, \n",
    "                               fault_collector, \n",
    "                               data_collector)\n",
    "        \n",
    "        if not error_flag:\n",
    "            error_flag = get_error_flag(fault_collector, colname)\n",
    "    # END OF LOOP over columns of sheet\n",
    "    \n",
    "    if not error_flag:  # prepare DB import of data IF no errors occurred yet\n",
    "        # generate import adapter from model\n",
    "        adapter = DjangoModelImportAdapter(model)\n",
    "        adapter.column_names = sheet.colnames\n",
    "        # feed data collector struct with sheet-derived data\n",
    "        data_collector[adapter.get_name()] = sheet\n",
    "        return adapter, fault_collector, row_mapper, column_mapper \n",
    "    return False, fault_collector, row_mapper, column_mapper \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importer2database(importer, data_collector):\n",
    "    error_flag = False\n",
    "    data_collector_subset = {}  # prepare struct for respective data chunk\n",
    "    for model_adapter_name in importer._DjangoModelImporter__adapters.keys():\n",
    "        sheet = data_collector[model_adapter_name]\n",
    "        model = importer._DjangoModelImporter__adapters[model_adapter_name].model\n",
    "        # Re-work data in sheet in order to fulfill foreignKey constraints (replace strings with objects)\n",
    "        msg = \"Checking ForeignKeys for '\" + model_adapter_name + \"'...\"\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        new_sheet = setup_foreign_keys_in_sheet(sheet, model)\n",
    "        if new_sheet:\n",
    "            throw_or_enqueue(\"info\", \"...done.\", main_msg_queue)\n",
    "            data_collector_subset[model_adapter_name] = new_sheet.get_internal_array()\n",
    "        else:\n",
    "            throw_or_enqueue(\"error\", \"...failed!\", main_msg_queue)\n",
    "            error_flag = True\n",
    "\n",
    "    if not error_flag:\n",
    "        msg = \"Writing data to database...\"\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        try:\n",
    "            save_data(importer, data_collector_subset, file_type=DB_DJANGO)\n",
    "        except BulkWriteError as bwe:\n",
    "            throw_or_enqueue(\"error\", \"FAILED!\", main_msg_queue)\n",
    "            throw_or_enqueue(\"error\", bwe, main_msg_queue)\n",
    "            return False\n",
    "        throw_or_enqueue(\"info\", \"...success!\", main_msg_queue)\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fault_collector(fault_collector, row_mappers, column_mappers):\n",
    "    \n",
    "    report = []\n",
    "    throw_or_enqueue(\"error\", \"### ISSUE REPORT ###\", report)\n",
    "\n",
    "    for sheet in fault_collector.keys():\n",
    "        throw_or_enqueue(\"error\", \"\\n=== Sheet '\" + sheet + \"' ===\", report)\n",
    "        for column in fault_collector[sheet].keys():\n",
    "            for error in fault_collector[sheet][column].keys():\n",
    "                if len(fault_collector[sheet][column][error]):\n",
    "                    throw_or_enqueue(\"error\", \"\\nColumn '\" + column + \"' - '\" + error + \"' errors in following rows:\", report)\n",
    "                    throw_or_enqueue(\"error\", \", \".join([str(row_mappers[sheet][x] + 2) for x in fault_collector[sheet][column][error]]), report)\n",
    "    for msg in report:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MAIN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This will delete all data model information contained in the current database.\n"
     ]
    }
   ],
   "source": [
    "# 1a. Core Model: Initialization\n",
    "main_msg_queue = []\n",
    "sheet_names = get_book(file_name=filepath).sheet_names()\n",
    "misses = [sn for sn in model2sheet_core.values() if not sn in sheet_names]\n",
    "if misses:\n",
    "    msg = \"Could not find following required worksheets in uploaded datamodel file:\\n\" + \"\\n\".join(misses)\n",
    "    throw_or_enqueue(\"error\", msg)\n",
    "    \n",
    "if write_mode == \"new\":\n",
    "    throw_or_enqueue(\"warning\", \"This will delete all data model information contained in the current database.\")\n",
    "    drop_tables_core()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['None', '%', 's', 'min', 'h', 'd', 'mo', 'a', 'words', 'figures', 'points', 'documents', 'U/l', '?', 'mg/dl', 'mg/l', 'ml/min', 'g/dl', 'G/l', 'mmHg', 'pg/ml', '1/¬µl']\n",
      "{'d', 's', 'U/l', 'mg/l', 'points', 'figures', 'g/dl', 'a', 'mg/dl', '?', 'mo', 'mmHg', '%', 'h', 'min', 'G/l', '1/¬µl', 'None', 'ml/min', 'pg/ml', 'documents', 'words'}\n"
     ]
    }
   ],
   "source": [
    "# 2a. Core Model: start iterative reading of contents from file\n",
    "dli = 0\n",
    "importer_collector = {}\n",
    "data_collector = {}\n",
    "fault_collector = {}\n",
    "column_mappers = {}\n",
    "row_mappers = {}\n",
    "unimported_codes = []\n",
    "error_flag = False\n",
    "for models in get_dependency_levels_core():\n",
    "    msg = \"Checking level \" + str(dli+1) + \" models...\"\n",
    "    throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "    importer = DjangoModelImporter()  # generate new importer (adapter queue) for current dependency level\n",
    "    \n",
    "    for model in models:\n",
    "        sheet_name = model2sheet_core[model]\n",
    "        \n",
    "        msg = \"    => \" + sheet_name + \" --> \" + model.__name__\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        \n",
    "        # Get original data (sheet) from file\n",
    "        sheet = get_sheet(file_name=filepath,\n",
    "                          sheet_name=sheet_name,\n",
    "                          name_columns_by_row=header_line_core[sheet_name],\n",
    "                          auto_detect_float=False,  # does not work\n",
    "                          auto_detect_datetime=False)\n",
    "    \n",
    "        adapter, fc, rm, cm = sheet2model_core(sheet, model, data_collector, unimported_codes)\n",
    "        fault_collector[sheet_name] = fc\n",
    "        row_mappers[sheet_name] = rm\n",
    "        column_mappers[sheet_name] = cm\n",
    "        # add adapter to importer (= queue for current dependency level)\n",
    "        if not adapter:\n",
    "            error_flag = True            \n",
    "        else:\n",
    "            importer.append(adapter)\n",
    "            if sheet_name == \"Codes\":\n",
    "                unimported_codes = sheet.column[\"Code\"]   # bulk import only\n",
    "                \n",
    "    # END OF LOOP over sheets (= models) of the current dependency level\n",
    "    \n",
    "    if error_flag:\n",
    "        msg = \"General errors on dependency level \" + str(dli+1) + \" models...\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        error_flag = True\n",
    "        break\n",
    "    importer_collector[dli] = importer\n",
    "    dli += 1\n",
    "# END OF LOOP over model dependency levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a. Write collected, model-adapted data into database\n",
    "if not error_flag:\n",
    "    for level in range(dli):\n",
    "        # fire up the import for a dependency level\n",
    "        msg = \"Importing level \" + str(level + 1) + \" model data...\"\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        importer = importer_collector[level]  # get level-specific subset of adapters (= one importer)\n",
    "        success = importer2database(importer, data_collector)\n",
    "        if not success:\n",
    "            error_flag = True\n",
    "            msg = \"Failed to write datamodel contents to DB (dep. level \" + str(level) + \")\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            error_flag = True\n",
    "        else:\n",
    "            msg = \"...done: Finished on level \" + str(level + 1) + \" models.\\n\"\n",
    "            throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "else:\n",
    "    throw_or_enqueue(\"error\", \"Errors occurred...\", main_msg_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking level 1 models...\n",
      "INFO:     => Sources --> DatamodelSource\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Abbreviation\n",
      "INFO: \t * Source\n",
      "INFO: \t * PID_colname\n",
      "INFO: \t * SITE_colname\n",
      "INFO: \t * TIMESTAMP_colname\n",
      "INFO: \t * Header_offset\n",
      "INFO:     => Units --> DatamodelUnit\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Unit\n",
      "INFO: \t * UCUM\n",
      "INFO: \t * Description\n",
      "INFO:     => Codes --> DatamodelCode\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Active\n",
      "INFO: \t * Code\n",
      "INFO: \t * Code_Description\n",
      "INFO: \t * Key\n",
      "INFO: \t * Value\n",
      "INFO: Checking level 2 models...\n",
      "INFO:     => Attributes --> DatamodelAttribute\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Active\n",
      "INFO: \t * Topic\n",
      "INFO: \t * Topic_Description\n",
      "INFO: \t * Umbrella\n",
      "INFO: \t * Umbrella_Description\n",
      "INFO: \t * Attribute\n",
      "INFO: \t * Attribute_Description\n",
      "INFO: \t * Attribute_Tooltip\n",
      "INFO: \t * Datatype\n",
      "INFO: \t * Domain\n",
      "WARNING: Removed useless leading/trailing whitespace characters from column 'Domain'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:18'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:3'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:70'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:85'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:4'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:4'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:4'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:4'\n",
      "WARNING: Found integer values or whitespace chars in domain declaration of a float-type variable: '0:40'\n",
      "WARNING: Sanitized entries in column 'Domain'\n",
      "INFO: \t * Unit\n",
      "INFO: Importing level 1 model data...\n",
      "INFO: Checking ForeignKeys for 'datamodelsource'...\n",
      "INFO: ...done.\n",
      "INFO: Checking ForeignKeys for 'datamodelunit'...\n",
      "INFO: ...done.\n",
      "INFO: Checking ForeignKeys for 'datamodelcode'...\n",
      "INFO: ...done.\n",
      "INFO: Writing data to database...\n",
      "INFO: ...success!\n",
      "INFO: ...done: Finished on level 1 models.\n",
      "\n",
      "INFO: Importing level 2 model data...\n",
      "INFO: Checking ForeignKeys for 'datamodelattribute'...\n",
      "INFO:  --> Resolving Foreign Keys...\n",
      "INFO: ...done.\n",
      "INFO: Writing data to database...\n",
      "INFO: ...success!\n",
      "INFO: ...done: Finished on level 2 models.\n",
      "\n",
      "INFO: No errors occured\n"
     ]
    }
   ],
   "source": [
    "# 4. Reporting\n",
    "for msg in main_msg_queue:\n",
    "    print(msg)\n",
    "main_msg_queue = []\n",
    "\n",
    "if error_flag:\n",
    "    print_fault_collector(fault_collector, row_mappers, column_mappers)\n",
    "else:\n",
    "    throw_or_enqueue(\"info\", \"No errors occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This will delete all mapping information contained in the current database.\n"
     ]
    }
   ],
   "source": [
    "# 1b. Mappings: Initialization\n",
    "main_msg_queue = []\n",
    "sheet_names = get_book(file_name=filepath).sheet_names()\n",
    "misses = [sn for sn in model2sheet_mapping.values() if not sn in sheet_names]\n",
    "if misses:\n",
    "    msg = \"Could not find following required worksheets in uploaded datamodel file:\\n\" + \"\\n\".join(misses)\n",
    "    throw_or_enqueue(\"error\", msg)\n",
    "    \n",
    "if write_mode == \"new\":\n",
    "    throw_or_enqueue(\"warning\", \"This will delete all mapping information contained in the current database.\")\n",
    "    drop_tables_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27: FORMULA( (SW_BNTTOT - 100) / 10) ) ==> FORMULA((SW_BNTTOT - 100) / 10))\n",
      "28: FORMULA( (SW_CERCP - 100) / 10) ) ==> FORMULA((SW_CERCP - 100) / 10))\n",
      "29: FORMULA( (SW_CERCPR - 100) / 10) ) ==> FORMULA((SW_CERCPR - 100) / 10))\n",
      "30: FORMULA( (SW_CERCPSAV - 100) / 10) ) ==> FORMULA((SW_CERCPSAV - 100) / 10))\n",
      "31: FORMULA( (SW_CERDISC - 100) / 10) ) ==> FORMULA((SW_CERDISC - 100) / 10))\n",
      "32: FORMULA( (SW_CERDRLCT - 100) / 10) ) ==> FORMULA((SW_CERDRLCT - 100) / 10))\n",
      "33: FORMULA( (SW_CERDRLIT - 100) / 10) ) ==> FORMULA((SW_CERDRLIT - 100) / 10))\n",
      "34: FORMULA( (SW_CERRL - 100) / 10) ) ==> FORMULA((SW_CERRL - 100) / 10))\n",
      "35: FORMULA( (SW_CERRL1CT - 100) / 10) ) ==> FORMULA((SW_CERRL1CT - 100) / 10))\n",
      "36: FORMULA( (SW_CERRL3CT - 100) / 10) ) ==> FORMULA((SW_CERRL3CT - 100) / 10))\n",
      "37: FORMULA( (SW_CERWLSAV - 100) / 10) ) ==> FORMULA((SW_CERWLSAV - 100) / 10))\n",
      "38: FORMULA( (SW_MMSTOT - 100) / 10) ) ==> FORMULA((SW_MMSTOT - 100) / 10))\n",
      "39: FORMULA( (SW_PFSTOT - 100) / 10) ) ==> FORMULA((SW_PFSTOT - 100) / 10))\n",
      "40: FORMULA( (SW_TMTA - 100) / 10) ) ==> FORMULA((SW_TMTA - 100) / 10))\n",
      "41: FORMULA( (SW_TMTB - 100) / 10) ) ==> FORMULA((SW_TMTB - 100) / 10))\n",
      "42: FORMULA( (SW_VFATOT - 100) / 10) ) ==> FORMULA((SW_VFATOT - 100) / 10))\n",
      "191: DRANGE(AC12MEMB) ==> DRANGE(AC12MEMB)\n",
      "192: DRANGE(AC12LNGB) ==> DRANGE(AC12LNGB)\n",
      "193: DRANGE(AC12PLNB) ==> DRANGE(AC12PLNB)\n",
      "194: DRANGE(AC12ATTB) ==> DRANGE(AC12ATTB)\n",
      "195: DRANGE(AC12OTHB) ==> DRANGE(AC12OTHB)\n",
      "196: DRANGE(AC2MEMA) ==> DRANGE(AC2MEMA)\n",
      "197: DRANGE(AC2LNGA) ==> DRANGE(AC2LNGA)\n",
      "198: DRANGE(AC2PLNA) ==> DRANGE(AC2PLNA)\n",
      "199: DRANGE(AC2ATTA) ==> DRANGE(AC2ATTA)\n",
      "200: DRANGE(AC2OTHA) ==> DRANGE(AC2OTHA)\n",
      "201: DRANGE(AC12MEMB) ==> DRANGE(AC12MEMB)\n",
      "202: DRANGE(AC12LNGB) ==> DRANGE(AC12LNGB)\n",
      "203: DRANGE(AC12PLNB) ==> DRANGE(AC12PLNB)\n",
      "204: DRANGE(AC12ATTB) ==> DRANGE(AC12ATTB)\n",
      "205: DRANGE(AC12OTHB) ==> DRANGE(AC12OTHB)\n",
      "206: DRANGE(AC2MEMA) ==> DRANGE(AC2MEMA)\n",
      "207: DRANGE(AC2LNGA) ==> DRANGE(AC2LNGA)\n",
      "208: DRANGE(AC2PLNA) ==> DRANGE(AC2PLNA)\n",
      "209: DRANGE(AC2ATTA) ==> DRANGE(AC2ATTA)\n",
      "210: DRANGE(AC2OTHA) ==> DRANGE(AC2OTHA)\n"
     ]
    }
   ],
   "source": [
    "# 2b. Mappings: start iterative reading of contents from file\n",
    "dli = 0\n",
    "importer_collector = {}\n",
    "data_collector = {}\n",
    "fault_collector = {}\n",
    "row_mappers = {}\n",
    "column_mappers = {}\n",
    "unimported_codemappings = {}\n",
    "error_flag = False\n",
    "for models in get_dependency_levels_mapping():\n",
    "    msg = \"Checking level \" + str(dli+1) + \" models...\"\n",
    "    throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "    importer = DjangoModelImporter()  # generate new importer (adapter queue) for current dependency level\n",
    "    \n",
    "    for model in models:\n",
    "        sheet_name = model2sheet_mapping[model]\n",
    "        \n",
    "        msg = \"    => \" + sheet_name + \" --> \" + model.__name__\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        \n",
    "        # Get original data (sheet) from file\n",
    "        sheet = get_sheet(file_name=filepath,\n",
    "                          sheet_name=sheet_name,\n",
    "                          name_columns_by_row=header_line_mapping[sheet_name],\n",
    "                          auto_detect_float=False,  # does not work\n",
    "                          auto_detect_datetime=False)\n",
    "    \n",
    "        adapter, fc, rm, cm = sheet2model_mapping(sheet, model, data_collector, unimported_codemappings)\n",
    "        fault_collector[sheet_name] = fc\n",
    "        row_mappers[sheet_name] = rm\n",
    "        column_mappers[sheet_name] = cm\n",
    "        # add adapter to importer (= queue for current dependency level)\n",
    "        if not adapter:\n",
    "            error_flag = True            \n",
    "        else:\n",
    "            importer.append(adapter)\n",
    "            if sheet_name == \"Code_Mappings\":                       # for bulk import only\n",
    "                pos_cm = sheet.colnames.index(\"Code_Mapping\")\n",
    "                pos_te = sheet.colnames.index(\"Target_Equivalent\")\n",
    "                for row in sheet:\n",
    "                    cm = row[pos_cm]\n",
    "                    if cm in unimported_codemappings:\n",
    "                        unimported_codemappings[cm].add(row[pos_te])\n",
    "                    else:\n",
    "                        unimported_codemappings[cm] = set([row[pos_te]])\n",
    "                for cm in unimported_codemappings:\n",
    "                    unimported_codemappings[cm] = list(unimported_codemappings[cm])\n",
    "                #unimported_codemappings = sheet.column[\"Code_Mapping\"]\n",
    "                \n",
    "    # END OF LOOP over sheets (= models) of the current dependency level\n",
    "    \n",
    "    if error_flag:\n",
    "        msg = \"General errors on dependency level \" + str(dli+1) + \" models...\"\n",
    "        throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "        break\n",
    "    importer_collector[dli] = importer\n",
    "    dli += 1\n",
    "# END OF LOOP over model dependency levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^\n",
      "<pyexcel_io.database.common.DjangoModelImporter object at 0x000001F4DBAC36A0>\n",
      "{'datamodelcodemapping': [[1, 'cm001', 'm', 'male', '0', ''], [1, 'cm001', 'f', 'female', '1', ''], [1, 'cm001', 'Male', 'male', '0', ''], [1, 'cm001', 'Female', 'female', '1', ''], [1, 'cm002', '0', 'no', '0', ''], [1, 'cm002', '1', 'yes', '1', ''], [1, 'cm002a', '0', 'no', '0', ''], [1, 'cm002a', '1', 'yes', '1', ''], [1, 'cm002a', '2', 'not mentioned', '2', ''], [1, 'cm002a', '3', 'equivocal', '3', ''], [1, 'cm002a', '4', 'unknown', '2', ''], [1, 'cm003', '1', 'Innerhalb der letzten sechs Monate', '[0:6]', ''], [1, 'cm003', '2', 'Vor sechs Monaten bis zwei Jahren', '[6:24]', ''], [1, 'cm003', '3', 'Vor zwei bis f√ºnf Jahren', '[24:60]', ''], [1, 'cm003', '4', 'Vor mehr als f√ºnf Jahren', '[60:]', ''], [1, 'cm004', 'SCA1', 'SCA1', '1', ''], [1, 'cm004', 'SCA2', 'SCA2', '2', ''], [1, 'cm004', 'SCA3', 'SCA3', '3', ''], [1, 'cm004', 'SCA6', 'SCA6', '6', ''], [1, 'cm005', 'Jan', '', '1', ''], [1, 'cm005', 'Feb', '', '2', ''], [1, 'cm005', 'Mar', '', '3', ''], [1, 'cm005', 'Apr', '', '4', ''], [1, 'cm005', 'May', '', '5', ''], [1, 'cm005', 'Jun', '', '6', ''], [1, 'cm005', 'Jul', '', '7', ''], [1, 'cm005', 'Aug', '', '8', ''], [1, 'cm005', 'Sep', '', '9', ''], [1, 'cm005', 'Oct', '', '10', ''], [1, 'cm005', 'Nov', '', '11', ''], [1, 'cm005', 'Dec', '', '12', '']]}\n",
      "^^^^^^^^^^^\n",
      "<pyexcel_io.database.common.DjangoModelImporter object at 0x000001F4DA244438>\n",
      "{'datamodelattributemapping': [[1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12MEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12LNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12PLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12ATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12OTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2MEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2LNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2PLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2ATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2OTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC12MEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_S_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC12LNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_S_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC12PLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_S_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC12ATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_S_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC12OTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_S_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC2MEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_E_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC2LNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_E_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC2PLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_E_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC2ATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_E_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'AC2OTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_E_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'ACXMEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_X_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'ACXLNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_X_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'ACXPLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_X_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'ACXATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_X_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'ACXOTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_X_TM)>, 'cm002a'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SEK_TMTA', <DatamodelAttribute: DatamodelAttribute object (TMTA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SEK_TMTB', <DatamodelAttribute: DatamodelAttribute object (TMTB_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_BNTTOT', <DatamodelAttribute: DatamodelAttribute object (BNT_SUM_Z)>, 'FORMULA((SW_BNTTOT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERCP', <DatamodelAttribute: DatamodelAttribute object (CERAD_CP_Z)>, 'FORMULA((SW_CERCP - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERCPR', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_Z)>, 'FORMULA((SW_CERCPR - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERCPSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPSAV_Z)>, 'FORMULA((SW_CERCPSAV - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERDISC', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLDIS_Z)>, 'FORMULA((SW_CERDISC - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERDRLCT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLRAI_Z)>, 'FORMULA((SW_CERDRLCT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERDRLIT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLINT_Z)>, 'FORMULA((SW_CERDRLIT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERRL', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSUM_Z)>, 'FORMULA((SW_CERRL - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERRL1CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL1ST_Z)>, 'FORMULA((SW_CERRL1CT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERRL3CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL3RD_Z)>, 'FORMULA((SW_CERRL3CT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_CERWLSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSAV_Z)>, 'FORMULA((SW_CERWLSAV - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_MMSTOT', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_Z)>, 'FORMULA((SW_MMSTOT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_PFSTOT', <DatamodelAttribute: DatamodelAttribute object (VFP_Z)>, 'FORMULA((SW_PFSTOT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_TMTA', <DatamodelAttribute: DatamodelAttribute object (TMTA_Z)>, 'FORMULA((SW_TMTA - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_TMTB', <DatamodelAttribute: DatamodelAttribute object (TMTB_Z)>, 'FORMULA((SW_TMTB - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SW_VFATOT', <DatamodelAttribute: DatamodelAttribute object (VFC_ANIM_Z)>, 'FORMULA((SW_VFATOT - 100) / 10))'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'sex', <DatamodelAttribute: DatamodelAttribute object (SEX)>, 'cm001'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'sex', <DatamodelAttribute: DatamodelAttribute object (SEX)>, 'cm001'], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'DOB', <DatamodelAttribute: DatamodelAttribute object (DOB)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'SEX', <DatamodelAttribute: DatamodelAttribute object (SEX)>, 'cm001'], [1, <DatamodelSource: DatamodelSource object (SCAregistry)>, 'sex', <DatamodelAttribute: DatamodelAttribute object (SEX)>, 'cm001'], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'Gender', <DatamodelAttribute: DatamodelAttribute object (SEX)>, 'cm001'], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'DNATestingRepeatsExpandedAllel', <DatamodelAttribute: DatamodelAttribute object (SHORT)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'DNATestingRepeatsNormalAllele', <DatamodelAttribute: DatamodelAttribute object (LONG)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'TypeOfSCA', <DatamodelAttribute: DatamodelAttribute object (SCACAT2)>, 'cm004'], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'GaitScore', <DatamodelAttribute: DatamodelAttribute object (SGAIT)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'StanceScore', <DatamodelAttribute: DatamodelAttribute object (SSTANCE)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SittingScore', <DatamodelAttribute: DatamodelAttribute object (SSITTING)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'Speechdisturbance', <DatamodelAttribute: DatamodelAttribute object (SDISTURB)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'RightFingerChaseScore', <DatamodelAttribute: DatamodelAttribute object (SCHASERI)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'LeftFingerChaseScore', <DatamodelAttribute: DatamodelAttribute object (SCHASELE)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'MeanFingerChaseScore', <DatamodelAttribute: DatamodelAttribute object (SFINGERMEAN)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'RightNosefingerTestScore', <DatamodelAttribute: DatamodelAttribute object (SFINGERRI)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'LeftNosefingerTestScore', <DatamodelAttribute: DatamodelAttribute object (SFINGERLE)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'MeanNosefingerTestScore', <DatamodelAttribute: DatamodelAttribute object (SFINGERNOSEMEAN)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'RightFastHandMovements', <DatamodelAttribute: DatamodelAttribute object (ALHANDRI)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'LeftFastHandMovements', <DatamodelAttribute: DatamodelAttribute object (ALHANDLE)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'MeanFastHandMovements', <DatamodelAttribute: DatamodelAttribute object (SALTHANDMEAN)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'RightHeelShinSlide', <DatamodelAttribute: DatamodelAttribute object (SHEELRI)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'LeftHeelShinSlide', <DatamodelAttribute: DatamodelAttribute object (SHEELLE)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'MeanHeelShinSlide', <DatamodelAttribute: DatamodelAttribute object (SHEELSHINMEAN)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'TotalSARAScore', <DatamodelAttribute: DatamodelAttribute object (SARASUM)>, ''], [1, <DatamodelSource: DatamodelSource object (SCAregistry)>, 'yob', <DatamodelAttribute: DatamodelAttribute object (DOB)>, ''], [1, <DatamodelSource: DatamodelSource object (CRCSCA)>, '_SARASUM', <DatamodelAttribute: DatamodelAttribute object (SARASUM)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'AGE', <DatamodelAttribute: DatamodelAttribute object (AGE_FV)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'PTGENDER', <DatamodelAttribute: DatamodelAttribute object (SEX)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'MMSE', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'CDRSB', <DatamodelAttribute: DatamodelAttribute object (CDR_SOB)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'CDGLOBAL', <DatamodelAttribute: DatamodelAttribute object (CDR_GLOBAL)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'APOE4', <DatamodelAttribute: DatamodelAttribute object (APOE_STATUS)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'ADAS11', <DatamodelAttribute: DatamodelAttribute object (ADAS_COG)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'MOCA', <DatamodelAttribute: DatamodelAttribute object (MOCA)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'GDSCALE', <DatamodelAttribute: DatamodelAttribute object (GDS)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'NPITOTAL', <DatamodelAttribute: DatamodelAttribute object (NPI)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'Q1', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'ADASQ4', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'ADAS13', <DatamodelAttribute: DatamodelAttribute object (ADAS_COG_13)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'PTEDUCAT', <DatamodelAttribute: DatamodelAttribute object (EDU_YEARS)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'TMTA', <DatamodelAttribute: DatamodelAttribute object (TMTA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'TMTB', <DatamodelAttribute: DatamodelAttribute object (TMTB_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ADNI)>, 'TMTBA', <DatamodelAttribute: DatamodelAttribute object (TMTBA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'AGE', <DatamodelAttribute: DatamodelAttribute object (AGE_FV)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'Sex', <DatamodelAttribute: DatamodelAttribute object (SEX)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'MMSE', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CDR_SOB', <DatamodelAttribute: DatamodelAttribute object (CDR_SOB)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CDR_Total', <DatamodelAttribute: DatamodelAttribute object (CDR_GLOBAL)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'APOE', <DatamodelAttribute: DatamodelAttribute object (APOE_STATUS)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'ADAS_COG', <DatamodelAttribute: DatamodelAttribute object (ADAS_COG)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'MOCA', <DatamodelAttribute: DatamodelAttribute object (MOCA)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'Geriatric_Depression', <DatamodelAttribute: DatamodelAttribute object (GDS)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'NPI', <DatamodelAttribute: DatamodelAttribute object (NPI)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CERAD_A_Total', <DatamodelAttribute: DatamodelAttribute object (VFC_ANIM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CERAD_B_Total', <DatamodelAttribute: DatamodelAttribute object (BNT_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CERAD_C_Total', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CERAD_D_Total', <DatamodelAttribute: DatamodelAttribute object (CERAD_CP_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CERAD_E_Correct', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_R)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'Baseline_Date', <DatamodelAttribute: DatamodelAttribute object (DOFV)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'Diagnosis', <DatamodelAttribute: DatamodelAttribute object (DIAG_TXT)>, ''], [1, <DatamodelSource: DatamodelSource object (ANM)>, 'CERAD_E_Intrusions', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLINT_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_BNTTOT', <DatamodelAttribute: DatamodelAttribute object (BNT_SUM_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_MMSTOT', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_TMTA', <DatamodelAttribute: DatamodelAttribute object (TMTA_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_TMTB', <DatamodelAttribute: DatamodelAttribute object (TMTB_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_TMTBA', <DatamodelAttribute: DatamodelAttribute object (TMTBA_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERCP', <DatamodelAttribute: DatamodelAttribute object (CERAD_CP_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERCPR', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERCPSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPSAV_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERDISC', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLDIS_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERDRLCT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLRAI_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERDRLIT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLINT_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERRL', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSUM_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERRL1CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL1ST_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERRL2CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL2ND_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERRL3CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL3RD_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_CERWLSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSAV_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_PFSTOT', <DatamodelAttribute: DatamodelAttribute object (VFP_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'Z_VFATOT', <DatamodelAttribute: DatamodelAttribute object (VFC_ANIM_Z)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_BNTTOT', <DatamodelAttribute: DatamodelAttribute object (BNT_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_MMSTOT', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_TMTA', <DatamodelAttribute: DatamodelAttribute object (TMTA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_TMTB', <DatamodelAttribute: DatamodelAttribute object (TMTB_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_TMTBA', <DatamodelAttribute: DatamodelAttribute object (TMTBA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERCP', <DatamodelAttribute: DatamodelAttribute object (CERAD_CP_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERCPR', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERCPSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPSAV_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERDISC', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLDIS_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERDRLCT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLRAI_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERDRLIT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLINT_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERRL', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERRL1CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL1ST_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERRL2CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL2ND_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERRL3CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL3RD_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_CERRWLSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSAV_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_PFSTOT', <DatamodelAttribute: DatamodelAttribute object (VFP_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'RW_VFATOT', <DatamodelAttribute: DatamodelAttribute object (VFC_ANIM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'BNTTOT', <DatamodelAttribute: DatamodelAttribute object (BNT_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'MMSTOT', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'TMTA', <DatamodelAttribute: DatamodelAttribute object (TMTA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'TMTB', <DatamodelAttribute: DatamodelAttribute object (TMTB_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'TMTBA', <DatamodelAttribute: DatamodelAttribute object (TMTBA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERCP', <DatamodelAttribute: DatamodelAttribute object (CERAD_CP_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERCPR', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERCPSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPSAV_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERDISC', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLDIS_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERDRLCT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLRAI_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERDRLIT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLINT_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERRL', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERRL1CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL1ST_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERRL2CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL2ND_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERRL3CT', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL3RD_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'CERRWLSAV', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLLSAV_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'PFSTOT', <DatamodelAttribute: DatamodelAttribute object (VFP_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'VFATOT', <DatamodelAttribute: DatamodelAttribute object (VFC_ANIM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adcnot1', <DatamodelAttribute: DatamodelAttribute object (BNT_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'cercp', <DatamodelAttribute: DatamodelAttribute object (CERAD_CP_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adcprtot', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPR_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adcprpct', <DatamodelAttribute: DatamodelAttribute object (CERAD_CPSAV_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'mmstot', <DatamodelAttribute: DatamodelAttribute object (MMSE_SUM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'tmta', <DatamodelAttribute: DatamodelAttribute object (TMTA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'tmtb', <DatamodelAttribute: DatamodelAttribute object (TMTB_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'tmtba', <DatamodelAttribute: DatamodelAttribute object (TMTBA_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'cervfg', <DatamodelAttribute: DatamodelAttribute object (VFC_ANIM_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'VFATOT', <DatamodelAttribute: DatamodelAttribute object (VFC_FOOD_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adasrlct', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLRAI_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adasl1ct', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL1ST_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adasl2ct', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL2ND_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'adasl3ct', <DatamodelAttribute: DatamodelAttribute object (CERAD_WLL3RD_R)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_A40_RESN', <DatamodelAttribute: DatamodelAttribute object (CSF_A40_LVL)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_A42_A40_RATIO', <DatamodelAttribute: DatamodelAttribute object (CSF_A42_A40_RATIO)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_A42_RESN', <DatamodelAttribute: DatamodelAttribute object (CSF_A42_LVL)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_LEU_RESN', <DatamodelAttribute: DatamodelAttribute object (CSF_LEU_CNT)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_PTP_RESN', <DatamodelAttribute: DatamodelAttribute object (CSF_PTP_LVL)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_TP_C_RESN', <DatamodelAttribute: DatamodelAttribute object (CSF_PROT_TOTAL)>, ''], [1, <DatamodelSource: DatamodelSource object (DBGA)>, 'LIQ_TTP_RESN', <DatamodelAttribute: DatamodelAttribute object (CSF_TTP_LVL)>, ''], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12MEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12LNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12PLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12ATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12OTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_S)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2MEM', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2LNG', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2PLN', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2ATT', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2OTH', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_E)>, 'cm002'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12MEMB', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_S_ONSET)>, 'DRANGE(AC12MEMB)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12LNGB', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_S_ONSET)>, 'DRANGE(AC12LNGB)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12PLNB', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_S_ONSET)>, 'DRANGE(AC12PLNB)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12ATTB', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_S_ONSET)>, 'DRANGE(AC12ATTB)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC12OTHB', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_S_ONSET)>, 'DRANGE(AC12OTHB)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2MEMA', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_E_ONSET)>, 'DRANGE(AC2MEMA)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2LNGA', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_E_ONSET)>, 'DRANGE(AC2LNGA)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2PLNA', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_E_ONSET)>, 'DRANGE(AC2PLNA)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2ATTA', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_E_ONSET)>, 'DRANGE(AC2ATTA)'], [1, <DatamodelSource: DatamodelSource object (DESCRIBE)>, 'AC2OTHA', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_E_ONSET)>, 'DRANGE(AC2OTHA)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12MEMB', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_S_ONSET)>, 'DRANGE(AC12MEMB)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12LNGB', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_S_ONSET)>, 'DRANGE(AC12LNGB)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12PLNB', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_S_ONSET)>, 'DRANGE(AC12PLNB)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12ATTB', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_S_ONSET)>, 'DRANGE(AC12ATTB)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC12OTHB', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_S_ONSET)>, 'DRANGE(AC12OTHB)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2MEMA', <DatamodelAttribute: DatamodelAttribute object (MEMDIS_E_ONSET)>, 'DRANGE(AC2MEMA)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2LNGA', <DatamodelAttribute: DatamodelAttribute object (LNGDIS_E_ONSET)>, 'DRANGE(AC2LNGA)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2PLNA', <DatamodelAttribute: DatamodelAttribute object (EXFDIS_E_ONSET)>, 'DRANGE(AC2PLNA)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2ATTA', <DatamodelAttribute: DatamodelAttribute object (ATTDIS_E_ONSET)>, 'DRANGE(AC2ATTA)'], [1, <DatamodelSource: DatamodelSource object (DELCODE)>, 'AC2OTHA', <DatamodelAttribute: DatamodelAttribute object (OTHDIS_E_ONSET)>, 'DRANGE(AC2OTHA)']]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^^^^^^^^\n",
      "<pyexcel_io.database.common.DjangoModelImporter object at 0x000001F4DBFADF28>\n",
      "{'datamodelcalculation': [[1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SFINGERMEAN_CALC', 'MEAN(SCHASERI, SCHASELE, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SFINGERMEAN', 'RANK(SFINGERMEAN_CALC, SFINGERMEAN, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SFINGERNOSEMEAN_CALC', 'MEAN(SFINGERRI, SFINGERLE, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SFINGERNOSEMEAN', 'RANK(SFINGERNOSEMEAN_CALC, SFINGERNOSEMEAN, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SALTHANDMEAN_CALC', 'MEAN(ALHANDRI, ALHANDLE, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SALTHANDMEAN', 'RANK(SALTHANDMEAN_CALC, SALTHANDMEAN, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SHEELSHINMEAN_CALC', 'MEAN(SHEELRI, SHEELLE, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SHEELSHINMEAN', 'RANK(SHEELSHINMEAN_CALC, SHEELSHINMEAN, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SARACALC', 'SUM(SGAIT, SSTANCE, SSITTING, SDISTURB, SFINGERMEAN, SFINGERNOSEMEAN, SALTHANDMEAN, SHEELSHINMEAN, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'SARASUM', 'RANK(SARACALC, SARASUM, 2d)', ''], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'ONSET_GAIT', 'SUM(DOB, WalkingProblemYears)', 'no Dt '], [1, 0, <DatamodelSource: DatamodelSource object (CRCSCA)>, 'DOB', 'DATE(DOBY, DOBM, DOBD)', 'no Dt '], [1, 0, <DatamodelSource: DatamodelSource object (DELCODE)>, 'CERAD_WLDIS_R', 'FORMULA(SUM(adasgcty, adasgctn) * 5)', ''], [1, 0, <DatamodelSource: DatamodelSource object (DELCODE)>, 'CERAD_WLINT_R', 'SUM(adasl1it, adasl2it, adasl3it, adasrlit)', ''], [1, 0, <DatamodelSource: DatamodelSource object (DELCODE)>, 'CERAD_WLLSUM_R', 'SUM(adasl1ct, adasl2ct, adasl3ct)', ''], [1, 0, <DatamodelSource: DatamodelSource object (DELCODE)>, 'CERAD_WLLSAV_R', 'FORMULA(adasrlct / adasl3ct * 100)', '']]}\n"
     ]
    }
   ],
   "source": [
    "# 3b. Write collected, model-mapped data into database\n",
    "if not error_flag:\n",
    "    for level in range(dli):\n",
    "        # fire up the import for a dependency level\n",
    "        msg = \"Importing level \" + str(level + 1) + \" model data...\"\n",
    "        throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "        importer = importer_collector[level]  # get level-specific subset of adapters (= one importer)\n",
    "        success = importer2database(importer, data_collector)\n",
    "        if not success:\n",
    "            error_flag = True\n",
    "            msg = \"Failed to write datamodel contents to DB (dep. level \" + str(level) + \")\"\n",
    "            throw_or_enqueue(\"error\", msg, main_msg_queue)\n",
    "            error_flag = True\n",
    "        else:\n",
    "            msg = \"...done: Finished on level \" + str(level + 1) + \" models.\\n\"\n",
    "            throw_or_enqueue(\"info\", msg, main_msg_queue)\n",
    "else:\n",
    "    throw_or_enqueue(\"error\", \"Errors occurred...\", main_msg_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Checking level 1 models...\n",
      "INFO:     => Code_Mappings --> DatamodelCodeMapping\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Active\n",
      "INFO: \t * Code_Mapping\n",
      "INFO: \t * Source_Value\n",
      "INFO: \t * Source_Value_Description\n",
      "INFO: \t * Target_Equivalent\n",
      "INFO: \t * Remarks\n",
      "INFO: Checking level 2 models...\n",
      "INFO:     => Attribute_Mappings --> DatamodelAttributeMapping\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Active\n",
      "INFO: \t * Source\n",
      "INFO: \t * Source_Attribute\n",
      "INFO: \t * Target_Attribute\n",
      "INFO: \t * Transformation\n",
      "INFO: Checking level 3 models...\n",
      "INFO:     => Calculations --> DatamodelCalculation\n",
      "INFO: \tWorking on columns:\n",
      "INFO: \t * Active\n",
      "INFO: \t * Workbench\n",
      "INFO: \t * Source\n",
      "INFO: \t * Attribute\n",
      "INFO: \t * Function\n",
      "INFO: \t * Remarks\n",
      "INFO: Importing level 1 model data...\n",
      "INFO: Checking ForeignKeys for 'datamodelcodemapping'...\n",
      "INFO: ...done.\n",
      "INFO: Writing data to database...\n",
      "INFO: ...success!\n",
      "INFO: ...done: Finished on level 1 models.\n",
      "\n",
      "INFO: Importing level 2 model data...\n",
      "INFO: Checking ForeignKeys for 'datamodelattributemapping'...\n",
      "INFO:  --> Resolving Foreign Keys...\n",
      "INFO:  --> Resolving Foreign Keys...\n",
      "INFO: ...done.\n",
      "INFO: Writing data to database...\n",
      "INFO: ...success!\n",
      "INFO: ...done: Finished on level 2 models.\n",
      "\n",
      "INFO: Importing level 3 model data...\n",
      "INFO: Checking ForeignKeys for 'datamodelcalculation'...\n",
      "INFO:  --> Resolving Foreign Keys...\n",
      "INFO: ...done.\n",
      "INFO: Writing data to database...\n",
      "INFO: ...success!\n",
      "INFO: ...done: Finished on level 3 models.\n",
      "\n",
      "= no errors =\n",
      "INFO: No errors occured\n"
     ]
    }
   ],
   "source": [
    "# 4. Reporting\n",
    "for msg in main_msg_queue:\n",
    "    print(msg)\n",
    "main_msg_queue = []\n",
    "\n",
    "if error_flag:\n",
    "    print(\"=== E R R O R S ===\")\n",
    "    print_fault_collector(fault_collector, row_mappers, column_mappers)\n",
    "else:\n",
    "    print(\"= no errors =\")\n",
    "    throw_or_enqueue(\"info\", \"No errors occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END OF MAIN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Core ###\n",
    "\n",
    "# 0. setup message queue\n",
    "main_msg_queue = []\n",
    "\n",
    "# 1. generate sheet object from input data (form => array => pyexcel sheet/book)\n",
    "###\n",
    "\n",
    "# 2. test sheet data vs. selected model; unimported_codes are those from a 'Codes' sheet, if not yet sent to DB\n",
    "data_collector = []\n",
    "unimported_codes = []   # or fill with contents\n",
    "adapter, fault_collector, row_mapper, column_mapper = sheet2model_core(sheet, model, data_collector, unimported_codes)\n",
    "# fault_collector should (structure, but no data); adapter might by False, if errors occured\n",
    "\n",
    "# 3. enqueue adapter into importer and write to DB\n",
    "importer = DjangoModelImporter()\n",
    "success = importer2database(importer, data_collector)\n",
    "\n",
    "# 4. read log and report errors\n",
    "for msg in main_msg_queue:\n",
    "    print(msg)\n",
    "main_msg_queue = []\n",
    "read_fault_collector(fault_collector, row_mapper, column_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Mappings ###\n",
    "\n",
    "# 0. setup message queue\n",
    "main_msg_queue = []\n",
    "\n",
    "# 1. generate sheet object from input data (form => array => pyexcel sheet/book)\n",
    "###\n",
    "\n",
    "# 2. test sheet data vs. selected model; unimported_codes are those from a 'Codes' sheet, if not yet sent to DB\n",
    "data_collector = []\n",
    "unimported_codes = []   # or fill with contents\n",
    "adapter, fault_collector, row_mapper, column_mapper = sheet2model_mapping(sheet, model, data_collector, unimported_codes)\n",
    "# fault_collector should (structure, but no data); adapter might by False, if errors occured\n",
    "\n",
    "# 3. enqueue adapter into importer and write to DB\n",
    "importer = DjangoModelImporter()\n",
    "success = importer2database(importer, data_collector)\n",
    "\n",
    "# 4. read log and report errors\n",
    "for msg in main_msg_queue:\n",
    "    print(msg)\n",
    "main_msg_queue = []\n",
    "read_fault_collector(fault_collector, row_mapper, column_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sources',\n",
       " 'Units',\n",
       " 'Attributes',\n",
       " 'Codes',\n",
       " 'Attribute_Mappings',\n",
       " 'Code_Mappings',\n",
       " 'Calculations',\n",
       " 'Questions+Remarks']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
